{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_challenge = './kaggle/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "train_solution = \"./kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\"\n",
    "\n",
    "eval_challenge = './kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json'\n",
    "eval_solution = './kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json'\n",
    "\n",
    "\n",
    "def DataMaker(challenge_data, solution_data):\n",
    "    \n",
    "    # Loading the data that contains the \"challenge\"\n",
    "    challenge = pd.read_json(challenge_data)\n",
    "    \n",
    "    # Loading the data that contains the \"Solution\"\n",
    "    with open(solution_data) as json_data:\n",
    "        solution = json.load(json_data) \n",
    "        \n",
    "    # getting alll the id values present in the dataset\n",
    "    all_ids = list(challenge.columns)\n",
    "    \n",
    "    # concatinating along the test the way it is done for the train part\n",
    "    for i in all_ids:\n",
    "        \n",
    "        # Getting the value of each cell for challenge dataset\n",
    "        substitute = challenge[f'{i}']['test'][0]\n",
    "        \n",
    "        # Creating a new \"output\" key value pair\n",
    "        substitute['output'] = solution[f'{i}'][0] \n",
    "        \n",
    "        # Changing the value to \"input : []\" and \"output : []\"\n",
    "        # instead of \"input : []\"\n",
    "        challenge[f'{i}']['test'] = substitute       \n",
    "        \n",
    "        \n",
    "    return challenge\n",
    "\n",
    "def InputOutputDataset(df):\n",
    "    \n",
    "    all_ids = list(df.columns)\n",
    "    new_df = pd.DataFrame(columns= ['id','input','output','input_shape','output_shape'])\n",
    "    for i in all_ids:\n",
    "        size = len(df[i]['train'])\n",
    "        for j in range(size) :\n",
    "            ip = df[i]['train'][j]['input']\n",
    "            op = df[i]['train'][j]['output']\n",
    "            ip_shape = np.array(df[i]['train'][j]['input']).shape\n",
    "            op_shape = np.array(df[i]['train'][j]['output']).shape\n",
    "            temp_df = pd.DataFrame()\n",
    "            temp_df['id'] = [f'{i}_train_{j}']\n",
    "            temp_df['input'] = [ip]\n",
    "            temp_df['output'] = [op]\n",
    "            temp_df['input_shape'] = [ip_shape]\n",
    "            temp_df['output_shape'] = [op_shape]\n",
    "\n",
    "            new_df = new_df._append(temp_df,ignore_index = True)\n",
    "    \n",
    "        ip = df[i]['test']['input']\n",
    "        op = df[i]['test']['output']\n",
    "        ip_shape = np.array(df[i]['test']['input']).shape\n",
    "        op_shape = np.array(df[i]['test']['output']).shape\n",
    "        temp_df = pd.DataFrame()\n",
    "        temp_df['id'] = [f'{i}_test']\n",
    "        temp_df['input'] = [ip]\n",
    "        temp_df['output'] = [op]\n",
    "        temp_df['input_shape'] = [ip_shape]\n",
    "        temp_df['output_shape'] = [op_shape]\n",
    "        new_df = new_df._append(temp_df,ignore_index = True)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "new_train_data = DataMaker(train_challenge,train_solution)\n",
    "new_train_data = InputOutputDataset(new_train_data)\n",
    "\n",
    "new_train_data.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
