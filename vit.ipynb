{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = ['#000000','#1E93FF','#F93C31','#4FCC30','#FFDC00',\n",
    "          '#999999','#E53AA3','#FF851B','#87D8F1','#921231','#555555']\n",
    "colormap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "def show_grid_side_by_side(*grids):\n",
    "    num_grids = len(grids)\n",
    "    fig, axes = plt.subplots(1, num_grids, figsize=(num_grids * 2.8, 2.8))\n",
    "\n",
    "    if num_grids == 1:\n",
    "        axes = [axes]  # 리스트로 변환하여 일관성 유지\n",
    "    \n",
    "    for ax, grid in zip(axes, grids):\n",
    "        if grid.ndim == 4:\n",
    "            grid = grid.squeeze()  # [1, 1, 30, 30] -> [30, 30]로 변환\n",
    "        elif grid.ndim == 3:\n",
    "            grid = grid[0]  # [1, 30, 30] -> [30, 30]로 변환\n",
    "            \n",
    "        ax.pcolormesh(grid, edgecolors=colors[-1], linewidth=0.5, cmap=colormap, vmin=0, vmax=10)\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_aspect('equal')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 예시:\n",
    "# predicted와 example_output이 [1, 1, 30, 30] 크기의 텐서라고 가정\n",
    "#show_grid_side_by_side(task_input, task_output, predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import ARC_Dataset\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.grid_size = img_size // patch_size\n",
    "        self.num_patches = self.grid_size ** 2\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=1, padding=1)\n",
    "        self.norm = nn.LayerNorm(embed_dim)  # BatchNorm2d 대신 LayerNorm 사용\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        x = x.flatten(2)  # (B, E, P)\n",
    "        x = x.transpose(1, 2)  # (B, P, E)\n",
    "        x = self.norm(x)  # LayerNorm을 여기에서 사용\n",
    "        return x\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim=768, num_heads=12, mlp_dim=3072, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_dim, embed_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.layernorm3 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_norm1 = self.layernorm1(x)\n",
    "        attn_output, _ = self.attention(x_norm1, x_norm1, x_norm1)\n",
    "        x = x + attn_output\n",
    "        x = self.layernorm2(x)\n",
    "\n",
    "        x_mlp_output = self.mlp(x)\n",
    "        x = x + x_mlp_output\n",
    "        x = self.layernorm3(x)\n",
    "        return x\n",
    "\n",
    "class TransformerHead(nn.Module):\n",
    "    def __init__(self, embed_dim, num_patches, num_classes, output_size=30):\n",
    "        super(TransformerHead, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Reshape [batch, 36, 512] -> [batch, 6, 6, 512] -> [batch, 512, 6, 6]\n",
    "        self.conv1 = nn.Conv2d(embed_dim, embed_dim, kernel_size=3, stride=1,)\n",
    "        self.conv2 = nn.Conv2d(embed_dim, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, 36, 512]\n",
    "        batch_size = x.size(0)\n",
    "        num_patches = int(x.size(1) ** 0.5)  # Assuming x.size(1) = 36, num_patches = 6\n",
    "\n",
    "        # Reshape to [batch, embed_dim, height, width]\n",
    "        x = x.view(batch_size, num_patches, num_patches, self.embed_dim)  # [batch, 6, 6, 512]\n",
    "        x = x.permute(0, 3, 1, 2)  # [batch, 512, 30, 30]\n",
    "\n",
    "        # Apply convolutions to aggregate spatial information\n",
    "        # x = self.conv1(x)  # [batch, 512, 30, 30]\n",
    "        # x = nn.functional.interpolate(x, size=(self.output_size, self.output_size), mode='bilinear', align_corners=False)\n",
    "        x = self.conv2(x)  # [batch, 11, 30, 30]\n",
    "\n",
    "        return x\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, img_size=30, patch_size=16, in_channels=3, embed_dim=768, num_heads=12, num_layers=12, output_channels=11, output_size=30, mlp_dim=3072, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n",
    "        self.pos_encoding = PositionalEncoding(embed_dim, max_len=self.patch_embed.num_patches)\n",
    "        self.pos_drop = nn.Dropout(p=dropout)\n",
    "        self.transformer_encoders = nn.Sequential(\n",
    "            *[TransformerEncoder(embed_dim, num_heads, mlp_dim, dropout) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = TransformerHead(embed_dim, self.patch_embed.num_patches, output_channels, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "        # print(\"Patch embedding output shape:\", x.shape)\n",
    "        # print(\"Patch embedding output sample:\", x[0, 0, :5].detach().cpu().numpy())  # Sample of first patch embedding\n",
    "\n",
    "        x = self.pos_encoding(x)\n",
    "        # print(\"After positional encoding shape:\", x.shape)\n",
    "        # print(\"After positional encoding sample:\", x[0, 0, :5].detach().cpu().numpy())  # Sample of first patch after positional encoding\n",
    "\n",
    "        x = self.pos_drop(x)\n",
    "        x = self.transformer_encoders(x)\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        # print(\"After transformer encoder shape:\", x.shape)\n",
    "        \n",
    "        logits = self.head(x)\n",
    "        return logits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 및 출력\n",
    "model_args =  {\n",
    "    \"img_size\": 30,\n",
    "    \"patch_size\": 3, # default: 16\n",
    "    \"in_channels\": 1,\n",
    "    \"embed_dim\": 256, # default: 768\n",
    "    \"num_heads\": 8, # default: 12\n",
    "    \"num_layers\": 8, # default: 12\n",
    "    \"mlp_dim\": 2048, # default: 3072\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_channels\": 11,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VisionTransformer(**model_args).to(device)\n",
    "# 입력 텐서 생성\n",
    "x = torch.randn(1, 1, 30, 30).to(device)\n",
    "\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "FLOPs: 7.578G\n",
      "파라미터 수: 8.426M\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "from thop import clever_format\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "outer_model = VisionTransformer(**model_args).to(device)\n",
    "\n",
    "# 입력 텐서 생성\n",
    "x = torch.randn(1, 1, 30, 30).to(device)\n",
    "\n",
    "# FLOPs 및 파라미터 수 계산\n",
    "try:\n",
    "    flops, params = profile(outer_model, inputs=(x,))\n",
    "    flops, params = clever_format([flops, params], \"%.3f\")\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"파라미터 수: {params}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during profiling: {e}\")\n",
    "    print(f\"Input shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bw_net_maml import BWNet_MAML\n",
    "\n",
    "# model = BWNet_MAML(embed_size=1).to(device)\n",
    "\n",
    "# # 입력 텐서 생성\n",
    "# x = torch.randn(1, 1, 30, 30).to(device)\n",
    "\n",
    "# # FLOPs 및 파라미터 수 계산\n",
    "# try:\n",
    "#     flops, params = profile(model, inputs=(x,))\n",
    "#     flops, params = clever_format([flops, params], \"%.3f\")\n",
    "#     print(f\"FLOPs: {flops}\")\n",
    "#     print(f\"파라미터 수: {params}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error during profiling: {e}\")\n",
    "#     print(f\"Input shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.0000e-04, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "weight = torch.ones(11).to('cuda')\n",
    "weight[0] = 0.0005  # 0은 무시\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 42/42 [09:31<00:00, 13.61s/it]\n",
      "Validation:  98%|█████████▊| 41/42 [09:49<00:14, 14.20s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 42/42 [09:58<00:00, 14.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Loss: 2.2678132561536937, Accuracy: 56.81818181818182%\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 42/42 [09:14<00:00, 13.20s/it]\n",
      "Validation:  98%|█████████▊| 41/42 [09:42<00:14, 14.21s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 42/42 [09:51<00:00, 14.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500, Loss: 2.2264115455058904, Accuracy: 57.89631564088086%\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 42/42 [09:14<00:00, 13.21s/it]\n",
      "Validation:  98%|█████████▊| 41/42 [09:48<00:14, 14.65s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 42/42 [09:56<00:00, 14.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/500, Loss: 2.2389360410877717, Accuracy: 57.66163184641446%\n",
      "Epoch 4/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 42/42 [09:30<00:00, 13.58s/it]\n",
      "Validation:  98%|█████████▊| 41/42 [09:59<00:14, 14.42s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 42/42 [10:07<00:00, 14.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/500, Loss: 2.1882047698331566, Accuracy: 57.37048277809147%\n",
      "Epoch 5/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 42/42 [09:12<00:00, 13.16s/it]\n",
      "Validation:  98%|█████████▊| 41/42 [09:40<00:14, 14.18s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 42/42 [09:49<00:00, 14.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/500, Loss: 2.2053767264319153, Accuracy: 58.835050818746474%\n",
      "Epoch 6/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 42/42 [09:11<00:00, 13.14s/it]\n",
      "Validation:  98%|█████████▊| 41/42 [09:40<00:14, 14.15s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 42/42 [09:49<00:00, 14.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/500, Loss: 2.2078208550810814, Accuracy: 59.443817052512706%\n",
      "Epoch 7/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 42/42 [09:12<00:00, 13.16s/it]\n",
      "Validation:  98%|█████████▊| 41/42 [09:40<00:14, 14.15s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 42/42 [09:49<00:00, 14.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/500, Loss: 2.2407862461673527, Accuracy: 57.4710615471485%\n",
      "Epoch 8/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 42/42 [09:21<00:00, 13.36s/it]\n",
      "Validation:  90%|█████████ | 38/42 [09:19<00:58, 14.55s/it]"
     ]
    }
   ],
   "source": [
    "from bw_net_maml import BWNet_MAML\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader_sw import ARC_Dataset\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "\n",
    "colors = ['#000000','#1E93FF','#F93C31','#4FCC30','#FFDC00',\n",
    "          '#999999','#E53AA3','#FF851B','#87D8F1','#921231','#555555']\n",
    "colormap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "\n",
    "\n",
    "train_challenge = './kaggle/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "train_solution = \"./kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\"\n",
    "eval_challenge = \"./kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json\"\n",
    "eval_solution = \"./kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\"\n",
    "\n",
    "kwargs = {\n",
    "    'epochs': 500,\n",
    "    'task_numbers': 10, #equal to the number of tasks\n",
    "    'task_data_num': 1,\n",
    "    'example_data_num': 20, #equal to inner model batch size\n",
    "    'inner_lr': 0.01,\n",
    "    'outer_lr': 0.001,\n",
    "    'embed_size': 1,\n",
    "}\n",
    "\n",
    "\n",
    "def criterion(y_pred, y):\n",
    "    y = y.long().squeeze(1)\n",
    "    weight = torch.ones(model_args['output_channels']).to(y.device)\n",
    "    weight[0] = 0.1\n",
    "    ce = F.cross_entropy(y_pred, y, weight=weight)\n",
    "    return ce\n",
    "\n",
    "# CUDA 사용 가능 여부 확인\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else device  \n",
    "print(f'Using {device} device')\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = ARC_Dataset(train_challenge, train_solution)\n",
    "train_loader = DataLoader(train_dataset, batch_size=kwargs['task_numbers'], shuffle=True)\n",
    "\n",
    "eval_dataset = ARC_Dataset(train_challenge, train_solution)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=kwargs['task_numbers'], shuffle=False)\n",
    "\n",
    "# Outer Model 정의\n",
    "outer_model =  VisionTransformer(**model_args).to(device)\n",
    "outer_optimizer = optim.AdamW(outer_model.parameters(), lr=kwargs['outer_lr'])\n",
    "\n",
    "# Inner Loop 업데이트 함수\n",
    "def inner_loop_update(model, example_input, example_output, inner_optimizer, criterion, steps):\n",
    "    for _ in range(steps):\n",
    "        model.train()\n",
    "        prediction = model(example_input)\n",
    "        loss = criterion(prediction, example_output)\n",
    "\n",
    "        inner_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        inner_optimizer.step()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(kwargs['epochs']):\n",
    "    print(f'Epoch {epoch+1}/{kwargs[\"epochs\"]}')\n",
    "    total_loss = 0\n",
    "    outer_model.train()\n",
    "    \n",
    "    for data in tqdm(train_loader, desc='Training'):\n",
    "        input_tensor, output_tensor, example_input, example_output = [d.to(device) for d in data]\n",
    "\n",
    "        task_losses = []\n",
    "        for task_number in range(input_tensor.shape[0]):\n",
    "            inner_model = deepcopy(outer_model)\n",
    "            inner_optimizer = optim.AdamW(inner_model.parameters(), lr=kwargs['inner_lr'])\n",
    "\n",
    "            inner_loop_update(inner_model, example_input[task_number], example_output[task_number],\n",
    "                              inner_optimizer, criterion, kwargs['example_data_num'])\n",
    "            \n",
    "            inner_model.eval()\n",
    "            task_prediction = inner_model(input_tensor[task_number])\n",
    "            task_loss = criterion(task_prediction, output_tensor[task_number])\n",
    "            task_losses.append(task_loss)\n",
    "        \n",
    "        meta_loss = torch.stack(task_losses).mean()\n",
    "        outer_optimizer.zero_grad()\n",
    "        meta_loss.backward()\n",
    "        outer_optimizer.step()\n",
    "\n",
    "        del meta_loss, task_losses\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Validation Loop\n",
    "    outer_model.eval()\n",
    "    validation_correct = 0\n",
    "    validation_total_samples = 0\n",
    "    total_loss = []\n",
    "\n",
    "    for batch_idx, data in enumerate(tqdm(eval_loader, desc='Validation')):\n",
    "        input_tensor, output_tensor, example_input, example_output = [d.to(device) for d in data]\n",
    "\n",
    "        for task_number in range(input_tensor.shape[0]):\n",
    "            inner_model = deepcopy(outer_model)\n",
    "            inner_optimizer = optim.AdamW(inner_model.parameters(), lr=kwargs['inner_lr'])\n",
    "\n",
    "            inner_loop_update(inner_model, example_input[task_number], example_output[task_number],\n",
    "                            inner_optimizer, criterion, kwargs['example_data_num'])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inner_model.eval()\n",
    "                task_input = input_tensor[task_number]\n",
    "                task_output = output_tensor[task_number]\n",
    "                task_prediction = inner_model(task_input)\n",
    "                task_loss = criterion(task_prediction, task_output)\n",
    "                total_loss.append(task_loss.item())  # task_loss.item()을 리스트에 추가\n",
    "\n",
    "                prediction_class = torch.argmax(task_prediction, dim=1, keepdim=True)\n",
    "\n",
    "                mask = task_output != 0\n",
    "                correct_predictions = (prediction_class == task_output) & mask\n",
    "                validation_correct += correct_predictions.sum().item()\n",
    "                validation_total_samples += mask.sum().item()\n",
    "\n",
    "                if batch_idx == len(eval_loader) - 1 and task_number == input_tensor.shape[0] - 1:\n",
    "                    show_grid_side_by_side(task_input.cpu(), task_output.cpu(), prediction_class.cpu())\n",
    "\n",
    "            del inner_model, inner_optimizer, task_input, task_output, task_prediction, mask, correct_predictions\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # 손실 값들의 평균 계산\n",
    "    mean_loss = sum(total_loss) / len(total_loss) if total_loss else 0\n",
    "    accuracy = 100 * validation_correct / validation_total_samples if validation_total_samples > 0 else 0\n",
    "    print(f'Epoch {epoch+1}/{kwargs[\"epochs\"]}, Loss: {mean_loss}, Accuracy: {accuracy}%')\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
