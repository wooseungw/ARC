{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "def show_grid_side_by_side(*grids):\n",
    "    num_grids = len(grids)\n",
    "    fig, axes = plt.subplots(1, num_grids, figsize=(num_grids * 2.8, 2.8))\n",
    "\n",
    "    if num_grids == 1:\n",
    "        axes = [axes]  # 리스트로 변환하여 일관성 유지\n",
    "    \n",
    "    for ax, grid in zip(axes, grids):\n",
    "        if grid.ndim == 4:\n",
    "            grid = grid.squeeze()  # [1, 1, 30, 30] -> [30, 30]로 변환\n",
    "        elif grid.ndim == 3:\n",
    "            grid = grid[0]  # [1, 30, 30] -> [30, 30]로 변환\n",
    "            \n",
    "        ax.pcolormesh(grid, linewidth=0.5, vmin=0, vmax=10)\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_aspect('equal')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 예시:\n",
    "# predicted와 example_output이 [1, 1, 30, 30] 크기의 텐서라고 가정\n",
    "#show_grid_side_by_side(task_input, task_output, predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader_sw import ARC_Dataset\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "from math import sqrt\n",
    "\n",
    "def cast_tuple(val, depth):\n",
    "    return val if isinstance(val, tuple) else (val,) * depth\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))\n",
    "        self.b = nn.Parameter(torch.zeros(1, dim, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        std = torch.var(x, dim=1, unbiased=False, keepdim=True).sqrt()\n",
    "        mean = torch.mean(x, dim=1, keepdim=True)\n",
    "        return (x - mean) / (std + self.eps) * self.g + self.b\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(self.norm(x))\n",
    "\n",
    "## 컨볼루션 임베딩\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, embed_dim, kernel_size, stride, padding, dropout=0.0):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Conv2d(1, \n",
    "                                   embed_dim, \n",
    "                                   kernel_size=kernel_size, \n",
    "                                   stride=stride, \n",
    "                                   padding=padding)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "## 인코더\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, *, dim=124, num_heads=4, dropout=0.1) -> None:\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x, _ = self.attn(x, x, x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim=124, num_heads=4, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                MultiheadAttention(dim=dim, num_heads=num_heads, dropout=dropout),\n",
    "                FeedForwardNetwork(dim=dim, hidden_dim=dim * 4, dropout=dropout)\n",
    "            ]) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        height = x.shape[2]\n",
    "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
    "\n",
    "        for attn, mlp in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = mlp(x) + x\n",
    "\n",
    "        x = rearrange(x, 'b (h w) c -> b c h w', h=height)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Head(nn.Module):\n",
    "    def __init__(self, input_dim = 256 ,dim=128, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(input_dim , dim, kernel_size=1),  \n",
    "            nn.Conv2d(dim, num_classes, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "## 디코더\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                lse_pool = logsumexp_2d(x)\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return x * scale\n",
    "\n",
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = F.sigmoid(x_out) # broadcasting\n",
    "        return x * scale\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate = SpatialGate()\n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.SpatialGate(x_out)\n",
    "        return x_out\n",
    "\n",
    "class ARC_Net(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        *,\n",
    "        dim=128,\n",
    "        num_heads=4,\n",
    "        num_layers=4,\n",
    "        num_classes=11,\n",
    "        dropout=0.1,\n",
    "        kernel_stride_padding=((1, 1, 0), (3, 1, 1))\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.stages = nn.ModuleList()\n",
    "\n",
    "        # 각 커널 크기, 스트라이드, 패딩을 튜플로 묶어서 처리\n",
    "        for (kernel_size, stride, padding) in kernel_stride_padding:\n",
    "            self.stages.append(\n",
    "                nn.ModuleList([\n",
    "                    Embedding(embed_dim=dim, kernel_size=kernel_size, stride=stride, padding=padding, dropout=dropout),\n",
    "                    Encoder(dim=dim, num_heads=num_heads, num_layers=num_layers, dropout=dropout)\n",
    "                ])\n",
    "            )\n",
    "        \n",
    "        # Decoder를 통해 attention을 적용하여 결합\n",
    "        self.decoder = Decoder(gate_channels = dim * len(kernel_stride_padding))  \n",
    "        self.head = Head(input_dim=dim * len(kernel_stride_padding), dim=dim, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        all_outputs = []\n",
    "\n",
    "        # 각 커널 크기, 스트라이드, 패딩에 대해 독립적으로 처리\n",
    "        for embedding, encoder in self.stages:\n",
    "            scale_x = embedding(x)\n",
    "            scale_x = encoder(scale_x)\n",
    "            all_outputs.append(scale_x)\n",
    "\n",
    "        # 다양한 커널 크기에서 추출된 특징을 병합\n",
    "        x = torch.cat(all_outputs, dim=1)\n",
    "        \n",
    "        # Decoder를 통해 어텐션 적용 및 결과와 결합\n",
    "        x = self.decoder(x)\n",
    "        # print(\"ch_sp:\",x.shape)\n",
    "        \n",
    "        # 병합된 특징을 헤드에 전달\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 및 출력\n",
    "model_args = {\n",
    "        'dim': 32,\n",
    "        'num_heads': 4,\n",
    "        'num_layers': 4,\n",
    "        'num_classes': 11,\n",
    "        'dropout': 0.1,\n",
    "        'kernel_stride_padding': ((1, 1, 0),(5, 1, 2))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 11, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ARC_Net(**model_args).to(device)\n",
    "# 입력 텐서 생성\n",
    "x = torch.randn(10, 1, 30, 30).to(device)\n",
    "\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "FLOPs: 62.906M\n",
      "파라미터 수: 71.347K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "ARC_Net                                                      [1, 11, 30, 30]           --\n",
       "├─ModuleList: 1-1                                            --                        --\n",
       "│    └─ModuleList: 2-1                                       --                        --\n",
       "│    │    └─Embedding: 3-1                                   [1, 32, 30, 30]           64\n",
       "│    │    └─Encoder: 3-2                                     [1, 32, 30, 30]           50,560\n",
       "│    └─ModuleList: 2-2                                       --                        --\n",
       "│    │    └─Embedding: 3-3                                   [1, 32, 30, 30]           832\n",
       "│    │    └─Encoder: 3-4                                     [1, 32, 30, 30]           50,560\n",
       "├─Decoder: 1-2                                               [1, 64, 30, 30]           --\n",
       "│    └─ChannelGate: 2-3                                      [1, 64, 30, 30]           --\n",
       "│    │    └─Sequential: 3-5                                  [1, 64]                   580\n",
       "│    │    └─Sequential: 3-6                                  [1, 64]                   (recursive)\n",
       "│    └─SpatialGate: 2-4                                      [1, 64, 30, 30]           --\n",
       "│    │    └─ChannelPool: 3-7                                 [1, 2, 30, 30]            --\n",
       "│    │    └─BasicConv: 3-8                                   [1, 1, 30, 30]            100\n",
       "├─Head: 1-3                                                  [1, 11, 30, 30]           --\n",
       "│    └─Sequential: 2-5                                       [1, 11, 30, 30]           --\n",
       "│    │    └─Conv2d: 3-9                                      [1, 32, 30, 30]           2,080\n",
       "│    │    └─Conv2d: 3-10                                     [1, 11, 30, 30]           363\n",
       "==============================================================================================================\n",
       "Total params: 105,139\n",
       "Trainable params: 105,139\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 3.16\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 11.85\n",
       "Params size (MB): 0.29\n",
       "Estimated Total Size (MB): 12.13\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thop import profile\n",
    "from thop import clever_format\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "outer_model = ARC_Net(**model_args).to(device)\n",
    "\n",
    "# 입력 텐서 생성\n",
    "x = torch.randn(1, 1, 30, 30).to(device)\n",
    "\n",
    "# FLOPs 및 파라미터 수 계산\n",
    "try:\n",
    "    flops, params = profile(outer_model, inputs=(x,))\n",
    "    flops, params = clever_format([flops, params], \"%.3f\")\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"파라미터 수: {params}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during profiling: {e}\")\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(outer_model, input_size=(1, 1, 30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bw_net_maml import BWNet_MAML\n",
    "\n",
    "# model = BWNet_MAML(embed_size=1).to(device)\n",
    "\n",
    "# # 입력 텐서 생성\n",
    "# x = torch.randn(1, 1, 30, 30).to(device)\n",
    "\n",
    "# # FLOPs 및 파라미터 수 계산\n",
    "# try:\n",
    "#     flops, params = profile(model, inputs=(x,))\n",
    "#     flops, params = clever_format([flops, params], \"%.3f\")\n",
    "#     print(f\"FLOPs: {flops}\")\n",
    "#     print(f\"파라미터 수: {params}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error during profiling: {e}\")\n",
    "#     print(f\"Input shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#weight = torch.ones(11).to('cuda')\n",
    "#weight[0] = 0.0005  # 0은 무시\n",
    "#print(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loop\n",
    "N개의 샘플 배치를 불러온다.\n",
    "1. 각 샘플에 대해 이너 모델을 아우터 모델에서 복사해 로스를 계산한다.\n",
    "2. 이너 모델의 파라미터를 업데이트한다.\n",
    "3. 업데이트 된 이너 모델을 바탕으로 테스크 셋에 대한 로스를 계산한다.\n",
    "4. 테스크 셋에 대한 로스를 저장한다.\n",
    "5. 모든 테스크 셋에 대해 로스가 구해지면 아우터 모델의 파라미터를 업데이트한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [04:00<00:00, 26.69s/it]\n",
      "Validation:  89%|████████▉ | 8/9 [04:44<00:33, 33.86s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [04:58<00:00, 33.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Loss: 1.8457640421561239, Accuracy: 50.20047708470791%\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [04:01<00:00, 26.81s/it]\n",
      "Validation:  89%|████████▉ | 8/9 [05:05<00:37, 37.51s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [05:20<00:00, 35.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500, Loss: 1.7893708114621178, Accuracy: 49.567071004415574%\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [04:30<00:00, 30.01s/it]\n",
      "Validation:  89%|████████▉ | 8/9 [05:22<00:38, 38.85s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [05:38<00:00, 37.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/500, Loss: 1.8361831913415458, Accuracy: 49.19047860731868%\n",
      "Epoch 4/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [04:29<00:00, 29.91s/it]\n",
      "Validation:  89%|████████▉ | 8/9 [05:21<00:38, 38.39s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [05:37<00:00, 37.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/500, Loss: 1.7631116221016518, Accuracy: 51.38811348525605%\n",
      "Epoch 5/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [04:28<00:00, 29.84s/it]\n",
      "Validation:  89%|████████▉ | 8/9 [05:18<00:37, 37.98s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [05:33<00:00, 37.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/500, Loss: 1.7555394259799353, Accuracy: 50.119271176978124%\n",
      "Epoch 6/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [04:17<00:00, 28.61s/it]\n",
      "Validation:  89%|████████▉ | 8/9 [06:18<00:44, 44.66s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [06:36<00:00, 44.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/500, Loss: 1.8293389263685107, Accuracy: 48.69918286555347%\n",
      "Epoch 7/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [05:42<00:00, 38.05s/it]\n",
      "Validation:  89%|████████▉ | 8/9 [05:47<00:38, 38.85s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [06:02<00:00, 40.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/500, Loss: 1.777306171974305, Accuracy: 51.06024463279704%\n",
      "Epoch 8/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [04:27<00:00, 29.70s/it]\n",
      "Validation:  89%|████████▉ | 8/9 [05:17<00:37, 37.98s/it]"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp4AAADTCAYAAAAoLxMIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAGrElEQVR4nO3dsWojVxiG4fFiMKkEksEuFULk3q3rFLmAXIbbVCpVpfVl5AK2SK3WvRVCXMpgG1QKQpTKW82s5Kz8nTPS85QjL/MzaJaXA+foZLPZbBoAAPhgn0oPAADAcRCeAABECE8AACKEJwAAEcITAIAI4QkAQITwBAAgQngCABAhPAEAiDjd9Q9/+vTLR86x1ekP3xe9P2X989ffxe79x7+/F7v3NrW+ly83l+FJ+mE0X5YeYW9KvpNNU/d7+fOPv5YeAYr4/OdvW//GiicAABHCEwCACOEJAECE8AQAIEJ4AgAQITwBAIgQngAARAhPAAAihCcAABHCEwCACOEJAEDEzr/VznFbzAat1yfTVXgSoGm638mm8V5CKevxsPOzs8fX4CT1suIJAECE8AQAIEJ4AgAQITwBAIgQngAARAhPAAAiHKfEThzPAnXxTkJ9HJm0nRVPAAAihCcAABHCEwCACOEJAECE8AQAIEJ4AgAQITwBAIgQngAARAhPAAAihCcAABHCEwCACL/V/o0ebi86P7u6ewpOArx5vt60Xj+/PwlPArxZj4et1/2++XGx4gkAQITwBAAgQngCABAhPAEAiBCeAABECE8AACIcp/SNHJkE9XFsEtTHsUk0jRVPAABChCcAABHCEwCACOEJAECE8AQAIMKudr5YzAadn02mq+AkwJuu99I7CeWsx8PW63bub2fFEwCACOEJAECE8AQAIEJ4AgAQITwBAIgQngAARDhOiS8czwL18V5CfRyb9P9Z8QQAIEJ4AgAQITwBAIgQngAARAhPAAAihCcAABHCEwCACOEJAECE8AQAIEJ4AgAQITwBAIgQngAARAhPAAAihCcAABHCEwCACOEJAECE8AQAIEJ4AgAQcVp6gBIWs0Hr9cl0FZ4EDtNovnz3v/FeQn3W42Hr9bPH1/AkHAorngAARAhPAAAihCcAABHCEwCACOEJAEDEUe5qt0sW6uO9hPrYvc6+WfEEACBCeAIAECE8AQCIEJ4AAEQITwAAIoQnAAARR3mcEkBtXm4ui95/NF8WvT9wHKx4AgAQITwBAIgQngAARAhPAAAihCcAABHCEwCACOEJAECE8AQAIEJ4AgAQITwBAIgQngAARPit9p5YzAat1yfTVeT+D7cXrdev7p4i94fadL2TTZN5L5+vN52fnd+ffPj9oUbr8bDzs7PH14O/fx9Y8QQAIEJ4AgAQITwBAIgQngAARAhPAAAihCcAABGOU+qJ1LFJXfZ5bFLpo6FgH0p/X/d9ZJL3kkNQ+siifd7/UI9msuIJAECE8AQAIEJ4AgAQITwBAIgQngAARNjVTpxdslAf7yXUpc8717/GiicAABHCEwCACOEJAECE8AQAIEJ4AgAQYVc7QAVG82XpEQA+nBVPAAAihCcAABHCEwCACOEJAECE8AQAIEJ4AgAQ0fvjlBazQednk+kqOMnuumYuPW8fnyV1qvU7/jW1zlzrXPTPejxsvX72+BqeZDdd8zZN+Zn79ixrYsUTAIAI4QkAQITwBAAgQngCABAhPAEAiOj9rvY+7uysdeZa56J/+vhdqnXmWueif/q247rmeWuerXZWPAEAiBCeAABECE8AACKEJwAAEcITAIAI4QkAQITwBAAgQngCABAhPAEAiBCeAABECE8AACKEJwAAEaelBwCOx8vNZekR3m00X5YeAeBgWPEEACBCeAIAECE8AQCIEJ4AAEQITwAAIoQnAAARwhMAgAjhCQBAhPAEACBCeAIAECE8AQCIEJ4AAEQITwAAIoQnAAARwhMAgAjhCQBAhPAEACBCeAIAEHFaeoC+eLi9aL1+dfcUngR483y9ab1+fn8SngRomqZZj4edn509vgYnoVZWPAEAiBCeAABECE8AACKEJwAAEcITAIAIu9p3ZPc61MfudaiLnetsY8UTAIAI4QkAQITwBAAgQngCABAhPAEAiBCeAABE9P44pcVs0PnZZLoKTnLYup6zZ0ybru/L6HN4kAPm/z7eaz0etl53BNL+dD3jpvGc31jxBAAgQngCABAhPAEAiBCeAABECE8AACJ6v6vd7s0Mz5n36Pq+vNx8F57kcHkneS+7qj+eZ7ydFU8AACKEJwAAEcITAIAI4QkAQITwBAAgQngCABDR++OUgP4YzZelRwCgICueAABECE8AACKEJwAAEcITAIAI4QkAQMTJZrPZlB4CAIDDZ8UTAIAI4QkAQITwBAAgQngCABAhPAEAiBCeAABECE8AACKEJwAAEcITAICI/wDO0NtQ+03WPQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [05:32<00:00, 36.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/500, Loss: 1.8215880294759403, Accuracy: 49.19047860731868%\n",
      "Epoch 9/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [04:22<00:00, 29.14s/it]\n",
      "Validation:  89%|████████▉ | 8/9 [04:46<00:34, 34.21s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [05:00<00:00, 33.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/500, Loss: 1.8005709236661118, Accuracy: 49.849261533776584%\n",
      "Epoch 10/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [04:07<00:00, 27.48s/it]\n",
      "Validation:  89%|████████▉ | 8/9 [05:21<00:38, 38.25s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [05:37<00:00, 37.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/500, Loss: 1.8283144632501078, Accuracy: 48.8006902502157%\n",
      "Epoch 11/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [04:44<00:00, 31.58s/it]\n",
      "Validation:  89%|████████▉ | 8/9 [05:32<00:39, 39.92s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [05:49<00:00, 38.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500, Loss: 1.819991776332935, Accuracy: 49.82692990915089%\n",
      "Epoch 12/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [04:38<00:00, 30.96s/it]\n",
      "Validation:  89%|████████▉ | 8/9 [05:38<00:40, 40.28s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x280 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [05:53<00:00, 39.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/500, Loss: 1.8024539966002853, Accuracy: 49.7000456783231%\n",
      "Epoch 13/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▍     | 4/9 [02:08<02:30, 30.06s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader_sw import ARC_Dataset\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "train_challenge = './kaggle/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "train_solution = \"./kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\"\n",
    "eval_challenge = \"./kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json\"\n",
    "eval_solution = \"./kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\"\n",
    "\n",
    "kwargs = {\n",
    "    'epochs': 500,\n",
    "    'task_numbers': 50,  # equal to the number of tasks\n",
    "    'task_data_num': 1,\n",
    "    'example_data_num': 5,  # equal to inner model batch size\n",
    "    'inner_lr': 0.01,\n",
    "    'outer_lr': 0.001,\n",
    "}\n",
    "\n",
    "\n",
    "def criterion(y_pred, y):\n",
    "    y = y.long().squeeze(1)\n",
    "    # print(y_pred.shape, y.shape)\n",
    "    weight = torch.ones(model_args['num_classes']).to(y.device)\n",
    "    weight[0] = 0.05\n",
    "    # weight[1] = 0.5\n",
    "    ce = F.cross_entropy(y_pred, y, weight=weight)\n",
    "    return ce\n",
    "\n",
    "# CUDA 사용 가능 여부 확인\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else device\n",
    "print(f'Using {device} device')\n",
    "\n",
    "train_dataset = ARC_Dataset(train_challenge, train_solution)\n",
    "train_loader = DataLoader(train_dataset, batch_size=kwargs['task_numbers'], shuffle=True, num_workers=8)\n",
    "\n",
    "eval_dataset = ARC_Dataset(eval_challenge, eval_solution)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=kwargs['task_numbers'], shuffle=False, num_workers=8)\n",
    "\n",
    "# Outer Model 정의\n",
    "outer_model = ARC_Net(**model_args).to(device)\n",
    "outer_optimizer = optim.AdamW(outer_model.parameters(), lr=kwargs['outer_lr'])\n",
    "\n",
    "# Inner Loop 업데이트 함수\n",
    "def inner_loop_update(model, example_input, example_output, inner_optimizer, criterion, steps):\n",
    "    for _ in range(steps):\n",
    "        model.train()\n",
    "        prediction = model(example_input)\n",
    "        \n",
    "        loss = criterion(prediction, example_output)\n",
    "\n",
    "        inner_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        inner_optimizer.step()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(kwargs['epochs']):\n",
    "    print(f'Epoch {epoch+1}/{kwargs[\"epochs\"]}')\n",
    "    total_loss = 0\n",
    "    outer_model.train()\n",
    "    \n",
    "    for data in tqdm(train_loader, desc='Training'):\n",
    "        input_tensor, output_tensor, example_input, example_output = [d.to(device) for d in data]\n",
    "        \n",
    "        task_losses = []\n",
    "        for task_number in range(input_tensor.shape[0]):\n",
    "            # 모델의 가중치만 복사하여 이너 모델 초기화\n",
    "            inner_model = ARC_Net(**model_args).to(device)\n",
    "            inner_model.load_state_dict(outer_model.state_dict())\n",
    "            \n",
    "            inner_optimizer = optim.AdamW(inner_model.parameters(), lr=kwargs['inner_lr'])\n",
    "            inner_loop_update(inner_model, example_input[task_number], example_output[task_number],\n",
    "                              inner_optimizer, criterion, kwargs['example_data_num'])\n",
    "            \n",
    "            inner_model.eval()\n",
    "            task_prediction = inner_model(input_tensor[task_number])\n",
    "            \n",
    "            task_loss = criterion(task_prediction, output_tensor[task_number])\n",
    "            task_losses.append(task_loss)\n",
    "        \n",
    "        meta_loss = torch.stack(task_losses).mean()\n",
    "        outer_optimizer.zero_grad()\n",
    "        meta_loss.backward()\n",
    "        outer_optimizer.step()\n",
    "        \n",
    "        del meta_loss, task_losses\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Validation Loop\n",
    "    outer_model.eval()\n",
    "    validation_correct = 0\n",
    "    validation_total_samples = 0\n",
    "    total_loss = []\n",
    "\n",
    "    for batch_idx, data in enumerate(tqdm(eval_loader, desc='Validation')):\n",
    "        input_tensor, output_tensor, example_input, example_output = [d.to(device) for d in data]\n",
    "\n",
    "        for task_number in range(input_tensor.shape[0]):\n",
    "            inner_model = ARC_Net(**model_args).to(device)\n",
    "            inner_model.load_state_dict(outer_model.state_dict())\n",
    "            \n",
    "            inner_optimizer = optim.AdamW(inner_model.parameters(), lr=kwargs['inner_lr'])\n",
    "            inner_loop_update(inner_model, example_input[task_number], example_output[task_number],\n",
    "                            inner_optimizer, criterion, kwargs['example_data_num'])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inner_model.eval()\n",
    "                task_input = input_tensor[task_number]\n",
    "                task_output = output_tensor[task_number]\n",
    "                task_prediction = inner_model(task_input)\n",
    "                task_loss = criterion(task_prediction, task_output)\n",
    "                total_loss.append(task_loss.item())\n",
    "\n",
    "                prediction_class = torch.argmax(task_prediction, dim=1, keepdim=True)\n",
    "\n",
    "                mask = task_output != 0\n",
    "                correct_predictions = (prediction_class == task_output) & mask\n",
    "                validation_correct += correct_predictions.sum().item()\n",
    "                validation_total_samples += mask.sum().item()\n",
    "\n",
    "                if batch_idx == len(eval_loader) - 1 and task_number == input_tensor.shape[0] - 1:\n",
    "                    show_grid_side_by_side(task_input.cpu(), task_output.cpu(), prediction_class.cpu())\n",
    "\n",
    "            del inner_model, inner_optimizer, task_input, task_output, task_prediction, mask, correct_predictions\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    mean_loss = sum(total_loss) / len(total_loss) if total_loss else 0\n",
    "    accuracy = 100 * validation_correct / validation_total_samples if validation_total_samples > 0 else 0\n",
    "    print(f'Epoch {epoch+1}/{kwargs[\"epochs\"]}, Loss: {mean_loss}, Accuracy: {accuracy}%')\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 30, 30])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 3, 3, 3],\n",
       "          [1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3],\n",
       "          [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "           3, 3, 3, 3, 3, 3, 3]]]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_class.shape\n",
    "prediction_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
