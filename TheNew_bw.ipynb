{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FEBlock(nn.Module):\n",
    "    def __init__(self, embed_size=1):\n",
    "        super(FEBlock, self).__init__()\n",
    "        self.stages = nn.ModuleList([])\n",
    "        \n",
    "        for n in range(1, 31):  # 1부터 30까지 크기 변화\n",
    "            # 1xn and nx1 convolutions with padding to maintain approximately the same size\n",
    "            conv_1xn = nn.Conv2d(1, 1, kernel_size=(1, n), padding=(0, (n - 1) // 2), groups=1)  # 1xn convolution\n",
    "            conv_nx1 = nn.Conv2d(1, embed_size, kernel_size=(n, 1), padding=((n - 1) // 2, 0), groups=1)  # nx1 convolution\n",
    "            \n",
    "            self.stages.append(nn.Sequential(\n",
    "                conv_1xn,\n",
    "                conv_nx1,\n",
    "            ))\n",
    "\n",
    "        self.conv1x1 = nn.Conv2d(30*embed_size, 1, kernel_size=1)  # 30채널을 1채널로 변환\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        for stage in self.stages:\n",
    "            out = stage(x)  # 각 stage를 통해 결과를 얻음\n",
    "            \n",
    "            # 최종 출력 크기를 강제로 30x30으로 맞추기 위해 패딩 추가\n",
    "            # out.shape[2] (height)와 out.shape[3] (width)를 확인해 30x30이 아니면 F.pad로 크기를 맞춤\n",
    "            if out.shape[2] != 30 or out.shape[3] != 30:\n",
    "                pad_h = 30 - out.shape[2]\n",
    "                pad_w = 30 - out.shape[3]\n",
    "                # 양 끝에 필요한 만큼의 패딩을 추가\n",
    "                out = F.pad(out, (0, pad_w, 0, pad_h))  # (왼쪽, 오른쪽, 위쪽, 아래쪽)\n",
    "            \n",
    "            features.append(out)  # 각 결과를 리스트에 저장\n",
    "        \n",
    "        # 30개의 feature를 채널 차원에서 결합하여 30채널로 변환\n",
    "        cat_features = torch.cat(features, dim=1)\n",
    "        out = self.conv1x1(cat_features)\n",
    "        return out\n",
    "\n",
    "# Example usage:\n",
    "x = torch.randn(10, 1, 30, 30)  # 배치 크기 10, 1채널, 30x30 입력\n",
    "model = FEBlock(embed_size=2)\n",
    "output = model(x)\n",
    "print(output.shape)  # (10, 30, 30, 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 11, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SelfAttentionBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SelfAttentionBlock, self).__init__()\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, 30*30))\n",
    "        self.layernorm1 = nn.LayerNorm(30*30)\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=30*30, num_heads=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), x.size(1), -1)  # (batch, 1, 30, 30) -> (batch, 1, 30*30)\n",
    "        batch_size = x.size(0)\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "        #print(cls_tokens.shape)\n",
    "        #print(x.shape)\n",
    "        x = x.squeeze(2)\n",
    "        #print(x.shape)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)  # (batch, 31, 30*30*embed_size)\n",
    "        #print(x.shape)\n",
    "        x = self.layernorm1(x)\n",
    "        #print(x.shape)\n",
    "        x, _ = self.self_attn(x, x, x)\n",
    "        #print(x.shape)\n",
    "        return x[:, 0].unsqueeze(1)  # (batch, 1, 30*30*embed_size)\n",
    "\n",
    "class HeadBlock(nn.Module):\n",
    "    def __init__(self, embed_size=1, num_classes=11):\n",
    "        super(HeadBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(30*30, 30*30*2)\n",
    "        self.fc2 = nn.Linear(30*30*2, 30*30)\n",
    "        self.fc3 = nn.Linear(30*30, 30*30)\n",
    "        self.conv = nn.Conv2d(1, num_classes, kernel_size=1)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = nn.Dropout(0.2)(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = nn.Dropout(0.2)(x)\n",
    "        x = self.fc3(x)\n",
    "        x = x.view(-1, 1, 30, 30)  # Reshape to (batch, 1, 30, 30)\n",
    "        x = self.conv(x)\n",
    "        x = self.log_softmax(x)\n",
    "        return x\n",
    "\n",
    "class BWNet_MAML(nn.Module):\n",
    "    def __init__(self, embed_size=1):\n",
    "        super(BWNet_MAML, self).__init__()\n",
    "        self.fe_block = FEBlock(embed_size=embed_size)\n",
    "        self.self_attn_block = SelfAttentionBlock()\n",
    "        self.head_block = HeadBlock()\n",
    "        \n",
    "\n",
    "    def forward(self, ex_input):\n",
    "        features = self.fe_block(ex_input)  # (batch, 30, 30*30*embed_size)\n",
    "        cls_feature = self.self_attn_block(features)  # (batch, 1, 30*30*embed_size)\n",
    "        out = self.head_block(cls_feature)  # (batch, 1, 30, 30)\n",
    "        # out = self.fc_final(out)  # (batch, 11, 30, 30)\n",
    "        return out\n",
    "\n",
    "input_tensor = torch.randn(1, 1, 30, 30)  # 입력 텐서 예시\n",
    "example_input = torch.randn(10, 1, 30, 30)  # 입력 텐서 예시\n",
    "# example_output = torch.randn(10, 1, 30, 30)  # 출력 텐서 예시\n",
    "\n",
    "model = BWNet_MAML(embed_size=2)\n",
    "output = model(example_input)\n",
    "\n",
    "print(output.shape)  # 최종 출력 크기를 확인\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
