{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))\n",
    "        self.b = nn.Parameter(torch.zeros(1, dim, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        std = torch.var(x, dim=1, unbiased=False, keepdim=True).sqrt()\n",
    "        mean = torch.mean(x, dim=1, keepdim=True)\n",
    "        return (x - mean) / (std + self.eps) * self.g + self.b\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(self.norm(x))\n",
    "\n",
    "class DsConv2d(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, kernel_size, padding, stride = 1, bias = True):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_in, kernel_size = kernel_size, padding = padding, groups = dim_in, stride = stride, bias=bias),\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size = 1, bias = bias)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "## 디코더\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                lse_pool = logsumexp_2d(x)\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return x * scale\n",
    "\n",
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = F.sigmoid(x_out) # broadcasting\n",
    "        return x * scale\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate = SpatialGate()\n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.SpatialGate(x_out)\n",
    "        return x_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from einops import rearrange\n",
    "from math import sqrt\n",
    "\n",
    "def cast_tuple(val, depth):\n",
    "    return val if isinstance(val, tuple) else (val,) * depth\n",
    "\n",
    "class EfficientSelfAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        heads,\n",
    "        reduction_ratio\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.scale = (dim // heads) ** -0.5\n",
    "        self.heads = heads\n",
    "\n",
    "        self.to_q = nn.Conv2d(dim, dim, 1, bias = False)\n",
    "        self.to_kv = nn.Conv2d(dim, dim * 2, reduction_ratio, stride = reduction_ratio, bias = False)\n",
    "        self.to_out = nn.Conv2d(dim, dim, 1, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, w = x.shape[-2:]\n",
    "        heads = self.heads\n",
    "\n",
    "        q, k, v = (self.to_q(x), *self.to_kv(x).chunk(2, dim = 1))\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b (h c) x y -> (b h) (x y) c', h = heads), (q, k, v))\n",
    "\n",
    "        sim = einsum('b i d, b j d -> b i j', q, k) * self.scale\n",
    "        attn = sim.softmax(dim = -1)\n",
    "\n",
    "        out = einsum('b i j, b j d -> b i d', attn, v)\n",
    "        out = rearrange(out, '(b h) (x y) c -> b (h c) x y', h = heads, x = h, y = w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class MixFeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        expansion_factor\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = dim * expansion_factor\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(dim, hidden_dim, 1),\n",
    "            DsConv2d(hidden_dim, hidden_dim, 3, padding = 1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(hidden_dim, dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "## 컨볼루션 임베딩\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, dim_in,dim_out, kernel_size, stride, padding):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Conv2d(dim_in, \n",
    "                                   dim_out, \n",
    "                                   kernel_size=kernel_size, \n",
    "                                   stride=stride, \n",
    "                                   padding=padding)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "    \n",
    "'''\n",
    "5. MiT (Mixer Transformer)\n",
    "이미지를 여러 스테이지로 처리합니다. 각 스테이지는 이미지를 패치로 나누고, 패치를 임베딩한 후, 여러 개의 Transformer 레이어를 적용합니다.\n",
    "이 과정은 이미지의 다양한 해상도에서 특징을 추출합니다. \n",
    "'''    \n",
    "class MiT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        channels,\n",
    "        dims,\n",
    "        heads,\n",
    "        ff_expansion,\n",
    "        reduction_ratio,\n",
    "        num_layers,\n",
    "        stage_kernel_stride_pad = ((7, 4, 3),  \n",
    "                                   (3, 2, 1), \n",
    "                                   (3, 2, 1), \n",
    "                                   (3, 2, 1))\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        dims = (channels, *dims)\n",
    "        dim_pairs = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        self.stages = nn.ModuleList([])\n",
    "\n",
    "        for (dim_in, dim_out), (kernel, stride, padding), num_layers, ff_expansion, heads, reduction_ratio in zip(\n",
    "            dim_pairs, stage_kernel_stride_pad, num_layers, ff_expansion, heads, reduction_ratio):\n",
    "            #여기서 너비와 높이가 같은 정사각형 패치를 사용합니다.\n",
    "            get_overlap_patches = nn.Unfold(kernel, stride = stride, padding = padding)\n",
    "            overlap_patch_embed = nn.Conv2d(dim_in * kernel ** 2, dim_out, 1)\n",
    "\n",
    "            layers = nn.ModuleList([])\n",
    "\n",
    "            for _ in range(num_layers):\n",
    "                layers.append(nn.ModuleList([\n",
    "                    PreNorm(dim_out, EfficientSelfAttention(dim = dim_out, heads = heads, reduction_ratio = reduction_ratio)),\n",
    "                    PreNorm(dim_out, MixFeedForward(dim = dim_out, expansion_factor = ff_expansion)),\n",
    "                ]))\n",
    "\n",
    "            self.stages.append(nn.ModuleList([\n",
    "                get_overlap_patches,\n",
    "                overlap_patch_embed,\n",
    "                layers\n",
    "            ]))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        return_layer_outputs = False\n",
    "    ):\n",
    "        h, w = x.shape[-2:]\n",
    "        \n",
    "        \n",
    "        layer_outputs = []\n",
    "        for (get_overlap_patches, overlap_embed, layers) in self.stages:\n",
    "            x = get_overlap_patches(x)\n",
    "            \n",
    "            num_patches = x.shape[-1]\n",
    "            ratio = int(sqrt((h * w) / num_patches))\n",
    "            \n",
    "            x = rearrange(x, 'b c (h w) -> b c h w', h = h // ratio)\n",
    "\n",
    "            x = overlap_embed(x)\n",
    "            for (attn, ff) in layers:\n",
    "                x = attn(x) + x\n",
    "                x = ff(x) + x\n",
    "\n",
    "            layer_outputs.append(x)\n",
    "\n",
    "        ret = x if not return_layer_outputs else layer_outputs\n",
    "        return ret\n",
    "    \n",
    "class Head(nn.Module):\n",
    "    def __init__(self, input_dim = 256 ,dim=128, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(input_dim , (input_dim//3)*2, kernel_size=1),  \n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d((input_dim//3)*2 , input_dim//3, kernel_size=1),  \n",
    "            nn.Conv2d(dim, num_classes, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "'''\n",
    "6. Segformer\n",
    "MiT를 통해 추출된 여러 스케일의 특징을 결합하고, 최종적으로 세그멘테이션 맵을 생성합니다.\n",
    "각 스테이지의 출력을 디코더 차원으로 매핑하고, 업샘플링하여 동일한 해상도로 만든 후, 이를 결합합니다.\n",
    "결합된 특징 맵을 사용하여 최종 세그멘테이션 맵을 생성합니다.\n",
    "'''\n",
    "class ARC_Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dims=(32, 64, 160, 256),\n",
    "        heads=(1, 2, 5, 8),\n",
    "        ff_expansion=(8, 8, 4, 4),\n",
    "        reduction_ratio=(8, 4, 2, 1),\n",
    "        num_layers=2,\n",
    "        channels=11,\n",
    "        num_classes=11,\n",
    "        kernel_stride_paddings = ((1, 1, 0),(3, 2, 1), (3, 2, 1), (3, 2, 1))\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        decoder_dim = dims[-1]\n",
    "        \n",
    "        dims, heads, ff_expansion, reduction_ratio, num_layers = map(\n",
    "            partial(cast_tuple, depth=len(kernel_stride_paddings)), (dims, heads, ff_expansion, reduction_ratio, num_layers))\n",
    "\n",
    "        \n",
    "        self.mit = MiT(\n",
    "            channels=channels,\n",
    "            dims=dims,\n",
    "            heads=heads,\n",
    "            ff_expansion=ff_expansion,\n",
    "            reduction_ratio=reduction_ratio,\n",
    "            num_layers=num_layers,\n",
    "            stage_kernel_stride_pad=kernel_stride_paddings\n",
    "        )\n",
    "\n",
    "        self.to_fused = nn.ModuleList([nn.Sequential(\n",
    "            nn.Conv2d(dim, decoder_dim, 1),\n",
    "            nn.Upsample(scale_factor=2 ** i)\n",
    "        ) for i, dim in enumerate(dims)])\n",
    "\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.cbam = CBAM(gate_channels = decoder_dim * len(kernel_stride_paddings) * 2)  \n",
    "        \n",
    "        self.cbam2 = CBAM(gate_channels = decoder_dim * len(kernel_stride_paddings) * 2)\n",
    "        \n",
    "        self.reduce = nn.Conv2d(decoder_dim * len(dims) * 2, decoder_dim * len(dims), 1)        \n",
    "        \n",
    "        self.to_segmentation = Head(decoder_dim*len(dims) * 3, decoder_dim*len(dims) , num_classes)\n",
    "        \n",
    "    def _fusion(self, x):\n",
    "        x = self.mit(x, return_layer_outputs=True)\n",
    "        # 드랍아웃 \n",
    "        x = [self.gelu(x) for x in x]\n",
    "        x = [self.dropout(x) for x in x]\n",
    "        fused = []\n",
    "        for output, to_fused in zip(x, self.to_fused):\n",
    "            x = to_fused(output)  # Conv2d 적용\n",
    "            # 업샘플링하여 공간 크기를 맞춥니다.\n",
    "            fused.append(x)\n",
    "        fused = torch.cat(fused, dim=1)\n",
    "        \n",
    "        return fused    \n",
    "    \n",
    "    def forward(self, x, ex_inputs, ex_outputs):\n",
    "        x = self._fusion(x) # [b,1,H,W] -> [b,dim_0,H,W],...,[b,dim_n, H//(n+1), W//(n+1)] \n",
    "                            # -> [b,dim_n, H, W],...,[b,dim_n, H, W] -> [b, dim_n * 2, H, W]\n",
    "                            # [b, 256, 32, 32]\n",
    "                            \n",
    "        # 예제 입력과 출력을 채널 차원으로 분할\n",
    "        n_examples = ex_inputs.size(1)//self.channels  # n_examples * channels (여기서는 3)\n",
    "        \n",
    "        # 예제 수만큼 반복하면서 예제 입력과 출력을 처리\n",
    "        fused = []\n",
    "        for i in range(n_examples):\n",
    "            ex_i = ex_inputs[:, i*self.channels:(i+1)*self.channels, :, :]  # [batch_size, 1, H, W]\n",
    "            ex_o = ex_outputs[:, i*self.channels:(i+1)*self.channels, :, :]  # [batch_size, 1, H, W]\n",
    "            \n",
    "            ex_i = self._fusion(ex_i)\n",
    "            ex_o = self._fusion(ex_o)\n",
    "            \n",
    "            ex_f = torch.cat([ex_i, ex_o], dim=1)\n",
    "            ex_f = self.cbam(ex_f)\n",
    "            ex_f = self.reduce(ex_f)\n",
    "            fused.append(ex_f)\n",
    "        \n",
    "        for i, ex_f in enumerate(fused):\n",
    "            ex_f = torch.cat([x, ex_f], dim=1)\n",
    "            ex_f = self.cbam2(ex_f)\n",
    "            ex_f = self.reduce(ex_f)\n",
    "            fused[i] = ex_f\n",
    "        \n",
    "        fused = torch.cat(fused, dim=1)\n",
    "        output = self.to_segmentation(fused)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 및 출력\n",
    "model_args = {\n",
    "    'dims': (16,32, 64, 128),\n",
    "    'heads': 4,\n",
    "    'ff_expansion': 4,\n",
    "    'reduction_ratio': (4,2,2,2),\n",
    "    'num_layers': (1,2,3,4),\n",
    "    'channels': 11,\n",
    "    'num_classes': 11,\n",
    "    'kernel_stride_paddings': ((3, 1, 1),(3, 2, 1),(3, 2, 1),(3, 2, 1))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dims, heads, ff_expansion, reduction_ratio, num_layers = map(\n",
    "#             partial(cast_tuple, depth=4), (model_args['dims'], \n",
    "#                                            model_args['heads'], \n",
    "#                                            model_args['ff_expansion'], \n",
    "#                                            model_args['reduction_ratio'], \n",
    "#                                            model_args['num_layers']))\n",
    "# mit = MiT(\n",
    "#         dims=dims,\n",
    "#         heads=heads,\n",
    "#         ff_expansion=ff_expansion,\n",
    "#         reduction_ratio=reduction_ratio,\n",
    "#         num_layers=num_layers,\n",
    "#         channels=model_args['channels'],\n",
    "#         stage_kernel_stride_pad=model_args['kernel_stride_paddings'],\n",
    "        \n",
    "#           )\n",
    "# x = torch.randn(10, 1, 30, 30)\n",
    "\n",
    "# print(\"Input shape:\", x.shape)\n",
    "# x = mit(x,return_layer_outputs = True)\n",
    "\n",
    "# print(\"Output shape:\", x[0].shape)\n",
    "# print(\"Output shape:\", x[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor = torch.randn(10, 1, 30, 30)\n",
    "# i = 0\n",
    "# h = tensor[:, i:i+11, :, :]\n",
    "# h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuse = [torch.randn(10, 256, 32, 32), torch.randn(10, 256, 32, 32), torch.randn(10, 256, 32, 32)]\n",
    "\n",
    "# x= torch.randn(10, 256, 32, 32)\n",
    "# for i , ex in enumerate(fuse) :\n",
    "#     print(\"fuse shape:\", ex.shape)\n",
    "#     ex = torch.cat([ex, x], dim=1)\n",
    "#     print(\"fuse shape:\", ex.shape)\n",
    "#     fuse[i] = ex\n",
    "#     print(\"fuse shape:\", fuse[i].shape)\n",
    "#     print(\"==================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torch/nn/functional.py:4790: UserWarning: The operator 'aten::im2col' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025535429/work/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  return torch._C._nn.im2col(input, _pair(kernel_size), _pair(dilation), _pair(padding), _pair(stride))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 11, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# CUDA 사용 가능 여부 확인\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else device\n",
    "print(f'Using {device} device')\n",
    "model = ARC_Net(**model_args).to(device)\n",
    "# 입력 텐서 생성\n",
    "x = torch.randn(10, 11, 32, 32).to(device)\n",
    "e_i, e_o = torch.randn(10, 33, 32, 32).to(device), torch.randn(10, 33, 32, 32).to(device)\n",
    "print(model(x,e_i,e_o).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type:depth-idx)                                                 Output Shape              Param #\n",
       "========================================================================================================================\n",
       "ARC_Net                                                                [1, 11, 32, 32]           --\n",
       "├─MiT: 1-1                                                             [1, 16, 32, 32]           --\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-2                                                            [1, 16, 32, 32]           --\n",
       "├─GELU: 1-3                                                            [1, 32, 16, 16]           --\n",
       "├─GELU: 1-4                                                            [1, 64, 8, 8]             --\n",
       "├─GELU: 1-5                                                            [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-6                                                         [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-7                                                         [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-8                                                         [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-9                                                         [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-2                                                 [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-5                                                [1, 128, 32, 32]          2,176\n",
       "│    │    └─Upsample: 3-6                                              [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-3                                                 [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-7                                                [1, 128, 16, 16]          4,224\n",
       "│    │    └─Upsample: 3-8                                              [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-4                                                 [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-9                                                [1, 128, 8, 8]            8,320\n",
       "│    │    └─Upsample: 3-10                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-5                                                 [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-11                                               [1, 128, 4, 4]            16,512\n",
       "│    │    └─Upsample: 3-12                                             [1, 128, 32, 32]          --\n",
       "├─MiT: 1-11                                                            [1, 16, 32, 32]           (recursive)\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-12                                                           [1, 16, 32, 32]           --\n",
       "├─GELU: 1-13                                                           [1, 32, 16, 16]           --\n",
       "├─GELU: 1-14                                                           [1, 64, 8, 8]             --\n",
       "├─GELU: 1-15                                                           [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-16                                                        [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-17                                                        [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-18                                                        [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-19                                                        [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-7                                                 [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-17                                               [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Upsample: 3-18                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-8                                                 [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-19                                               [1, 128, 16, 16]          (recursive)\n",
       "│    │    └─Upsample: 3-20                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-9                                                 [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-21                                               [1, 128, 8, 8]            (recursive)\n",
       "│    │    └─Upsample: 3-22                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-10                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-23                                               [1, 128, 4, 4]            (recursive)\n",
       "│    │    └─Upsample: 3-24                                             [1, 128, 32, 32]          --\n",
       "├─MiT: 1-21                                                            [1, 16, 32, 32]           (recursive)\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-22                                                           [1, 16, 32, 32]           --\n",
       "├─GELU: 1-23                                                           [1, 32, 16, 16]           --\n",
       "├─GELU: 1-24                                                           [1, 64, 8, 8]             --\n",
       "├─GELU: 1-25                                                           [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-26                                                        [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-27                                                        [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-28                                                        [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-29                                                        [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-12                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-29                                               [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Upsample: 3-30                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-13                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-31                                               [1, 128, 16, 16]          (recursive)\n",
       "│    │    └─Upsample: 3-32                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-14                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-33                                               [1, 128, 8, 8]            (recursive)\n",
       "│    │    └─Upsample: 3-34                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-15                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-35                                               [1, 128, 4, 4]            (recursive)\n",
       "│    │    └─Upsample: 3-36                                             [1, 128, 32, 32]          --\n",
       "├─CBAM: 1-31                                                           [1, 1024, 32, 32]         --\n",
       "│    └─ChannelGate: 2-16                                               [1, 1024, 32, 32]         --\n",
       "│    │    └─Sequential: 3-37                                           [1, 1024]                 132,160\n",
       "│    │    └─Sequential: 3-38                                           [1, 1024]                 (recursive)\n",
       "│    └─SpatialGate: 2-17                                               [1, 1024, 32, 32]         --\n",
       "│    │    └─ChannelPool: 3-39                                          [1, 2, 32, 32]            --\n",
       "│    │    └─BasicConv: 3-40                                            [1, 1, 32, 32]            100\n",
       "├─Conv2d: 1-32                                                         [1, 512, 32, 32]          524,800\n",
       "├─MiT: 1-33                                                            [1, 16, 32, 32]           (recursive)\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-34                                                           [1, 16, 32, 32]           --\n",
       "├─GELU: 1-35                                                           [1, 32, 16, 16]           --\n",
       "├─GELU: 1-36                                                           [1, 64, 8, 8]             --\n",
       "├─GELU: 1-37                                                           [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-38                                                        [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-39                                                        [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-40                                                        [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-41                                                        [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-19                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-45                                               [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Upsample: 3-46                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-20                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-47                                               [1, 128, 16, 16]          (recursive)\n",
       "│    │    └─Upsample: 3-48                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-21                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-49                                               [1, 128, 8, 8]            (recursive)\n",
       "│    │    └─Upsample: 3-50                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-22                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-51                                               [1, 128, 4, 4]            (recursive)\n",
       "│    │    └─Upsample: 3-52                                             [1, 128, 32, 32]          --\n",
       "├─MiT: 1-43                                                            [1, 16, 32, 32]           (recursive)\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-44                                                           [1, 16, 32, 32]           --\n",
       "├─GELU: 1-45                                                           [1, 32, 16, 16]           --\n",
       "├─GELU: 1-46                                                           [1, 64, 8, 8]             --\n",
       "├─GELU: 1-47                                                           [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-48                                                        [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-49                                                        [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-50                                                        [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-51                                                        [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-24                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-57                                               [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Upsample: 3-58                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-25                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-59                                               [1, 128, 16, 16]          (recursive)\n",
       "│    │    └─Upsample: 3-60                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-26                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-61                                               [1, 128, 8, 8]            (recursive)\n",
       "│    │    └─Upsample: 3-62                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-27                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-63                                               [1, 128, 4, 4]            (recursive)\n",
       "│    │    └─Upsample: 3-64                                             [1, 128, 32, 32]          --\n",
       "├─CBAM: 1-53                                                           [1, 1024, 32, 32]         (recursive)\n",
       "│    └─ChannelGate: 2-28                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─Sequential: 3-65                                           [1, 1024]                 (recursive)\n",
       "│    │    └─Sequential: 3-66                                           [1, 1024]                 (recursive)\n",
       "│    └─SpatialGate: 2-29                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─ChannelPool: 3-67                                          [1, 2, 32, 32]            --\n",
       "│    │    └─BasicConv: 3-68                                            [1, 1, 32, 32]            (recursive)\n",
       "├─Conv2d: 1-54                                                         [1, 512, 32, 32]          (recursive)\n",
       "├─MiT: 1-55                                                            [1, 16, 32, 32]           (recursive)\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-56                                                           [1, 16, 32, 32]           --\n",
       "├─GELU: 1-57                                                           [1, 32, 16, 16]           --\n",
       "├─GELU: 1-58                                                           [1, 64, 8, 8]             --\n",
       "├─GELU: 1-59                                                           [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-60                                                        [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-61                                                        [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-62                                                        [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-63                                                        [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-31                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-73                                               [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Upsample: 3-74                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-32                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-75                                               [1, 128, 16, 16]          (recursive)\n",
       "│    │    └─Upsample: 3-76                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-33                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-77                                               [1, 128, 8, 8]            (recursive)\n",
       "│    │    └─Upsample: 3-78                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-34                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-79                                               [1, 128, 4, 4]            (recursive)\n",
       "│    │    └─Upsample: 3-80                                             [1, 128, 32, 32]          --\n",
       "├─MiT: 1-65                                                            [1, 16, 32, 32]           (recursive)\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-66                                                           [1, 16, 32, 32]           --\n",
       "├─GELU: 1-67                                                           [1, 32, 16, 16]           --\n",
       "├─GELU: 1-68                                                           [1, 64, 8, 8]             --\n",
       "├─GELU: 1-69                                                           [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-70                                                        [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-71                                                        [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-72                                                        [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-73                                                        [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-36                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-85                                               [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Upsample: 3-86                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-37                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-87                                               [1, 128, 16, 16]          (recursive)\n",
       "│    │    └─Upsample: 3-88                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-38                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-89                                               [1, 128, 8, 8]            (recursive)\n",
       "│    │    └─Upsample: 3-90                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-39                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-91                                               [1, 128, 4, 4]            (recursive)\n",
       "│    │    └─Upsample: 3-92                                             [1, 128, 32, 32]          --\n",
       "├─CBAM: 1-75                                                           [1, 1024, 32, 32]         (recursive)\n",
       "│    └─ChannelGate: 2-40                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─Sequential: 3-93                                           [1, 1024]                 (recursive)\n",
       "│    │    └─Sequential: 3-94                                           [1, 1024]                 (recursive)\n",
       "│    └─SpatialGate: 2-41                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─ChannelPool: 3-95                                          [1, 2, 32, 32]            --\n",
       "│    │    └─BasicConv: 3-96                                            [1, 1, 32, 32]            (recursive)\n",
       "├─Conv2d: 1-76                                                         [1, 512, 32, 32]          (recursive)\n",
       "├─CBAM: 1-77                                                           [1, 1024, 32, 32]         --\n",
       "│    └─ChannelGate: 2-42                                               [1, 1024, 32, 32]         --\n",
       "│    │    └─Sequential: 3-97                                           [1, 1024]                 132,160\n",
       "│    │    └─Sequential: 3-98                                           [1, 1024]                 (recursive)\n",
       "│    └─SpatialGate: 2-43                                               [1, 1024, 32, 32]         --\n",
       "│    │    └─ChannelPool: 3-99                                          [1, 2, 32, 32]            --\n",
       "│    │    └─BasicConv: 3-100                                           [1, 1, 32, 32]            100\n",
       "├─Conv2d: 1-78                                                         [1, 512, 32, 32]          (recursive)\n",
       "├─CBAM: 1-79                                                           [1, 1024, 32, 32]         (recursive)\n",
       "│    └─ChannelGate: 2-44                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─Sequential: 3-101                                          [1, 1024]                 (recursive)\n",
       "│    │    └─Sequential: 3-102                                          [1, 1024]                 (recursive)\n",
       "│    └─SpatialGate: 2-45                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─ChannelPool: 3-103                                         [1, 2, 32, 32]            --\n",
       "│    │    └─BasicConv: 3-104                                           [1, 1, 32, 32]            (recursive)\n",
       "├─Conv2d: 1-80                                                         [1, 512, 32, 32]          (recursive)\n",
       "├─CBAM: 1-81                                                           [1, 1024, 32, 32]         (recursive)\n",
       "│    └─ChannelGate: 2-46                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─Sequential: 3-105                                          [1, 1024]                 (recursive)\n",
       "│    │    └─Sequential: 3-106                                          [1, 1024]                 (recursive)\n",
       "│    └─SpatialGate: 2-47                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─ChannelPool: 3-107                                         [1, 2, 32, 32]            --\n",
       "│    │    └─BasicConv: 3-108                                           [1, 1, 32, 32]            (recursive)\n",
       "├─Conv2d: 1-82                                                         [1, 512, 32, 32]          (recursive)\n",
       "├─Head: 1-83                                                           [1, 11, 32, 32]           --\n",
       "│    └─Sequential: 2-48                                                [1, 11, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-109                                              [1, 1024, 32, 32]         1,573,888\n",
       "│    │    └─GELU: 3-110                                                [1, 1024, 32, 32]         --\n",
       "│    │    └─Dropout: 3-111                                             [1, 1024, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-112                                              [1, 512, 32, 32]          524,800\n",
       "│    │    └─Conv2d: 3-113                                              [1, 11, 32, 32]           5,643\n",
       "========================================================================================================================\n",
       "Total params: 5,795,523\n",
       "Trainable params: 5,795,523\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.98\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.32\n",
       "Forward/backward pass size (MB): 101.35\n",
       "Params size (MB): 23.18\n",
       "Estimated Total Size (MB): 124.85\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thop import profile\n",
    "from thop import clever_format\n",
    "\n",
    "# CUDA 사용 가능 여부 확인\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else device\n",
    "print(f'Using {device} device')\n",
    "outer_model = ARC_Net(**model_args).to(device)\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(outer_model, input_size=((1, 11, 32, 32), (1, 33, 32, 32), (1, 33, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor = torch.zeros(1, 30, 30)\n",
    "# tensor = F.one_hot(tensor.long(), num_classes=11)\n",
    "# print(tensor.shape)\n",
    "# tensor = tensor.permute(0, 3, 1, 2)\n",
    "# print(tensor.shape)\n",
    "# tensor = tensor.squeeze(0)    \n",
    "# print(tensor.shape)\n",
    "# print(tensor.dtype)\n",
    "# tensor = tensor.to(torch.float32)  # 수정된 부분\n",
    "# print(tensor.dtype)\n",
    "# tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 11, 32, 32]) torch.Size([10, 1, 32, 32]) torch.Size([10, 33, 32, 32]) torch.Size([10, 33, 32, 32])\n",
      "torch.float32 torch.float32 torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "def one_hot_encoding(tensor):\n",
    "    tensor = F.one_hot(tensor.long(), num_classes=11)\n",
    "    tensor = tensor.permute(0, 3, 1, 2)\n",
    "    tensor = tensor.squeeze(0)\n",
    "    # 여기서 명시적으로 dtype을 float32로 설정합니다\n",
    "    tensor = tensor.to(torch.float32)  # 수정된 부분\n",
    "    return tensor\n",
    "\n",
    "\n",
    "class ARC_Dataset(Dataset):\n",
    "    def __init__(self, challenges, solution, task_data_num=1, example_data_num=3, max_combinations=10):\n",
    "        challenges = load_json(challenges)\n",
    "        solution = load_json(solution)\n",
    "        self.data = []\n",
    "        self.task_data_num = task_data_num\n",
    "        self.example_data_num = example_data_num\n",
    "        self.max_combinations = max_combinations\n",
    "\n",
    "        for key, value in challenges.items():\n",
    "            for i in range(len(value['test'])):\n",
    "                task_input = value['test'][i]['input']\n",
    "                task_output = solution[key][i]\n",
    "                example_list = value['train'].copy()\n",
    "\n",
    "                n_examples = len(example_list)  # 원래 예제의 개수\n",
    "\n",
    "                # 예제 수가 example_data_num보다 적으면 현재 작업의 예제를 복제하여 채움\n",
    "                if n_examples < self.example_data_num:\n",
    "                    while len(example_list) < self.example_data_num:\n",
    "                        example_list.append(random.choice(example_list))\n",
    "\n",
    "                    # 조합은 예제 리스트 자체로 설정\n",
    "                    ex_combinations = [tuple(example_list)]\n",
    "                else:\n",
    "                    # 예제의 조합 생성\n",
    "                    ex_combinations = list(combinations(example_list, self.example_data_num))\n",
    "\n",
    "                    # 조합의 수를 제한\n",
    "                    if len(ex_combinations) > self.max_combinations:\n",
    "                        ex_combinations = random.sample(ex_combinations, self.max_combinations)\n",
    "\n",
    "                for ex_combo in ex_combinations:\n",
    "                    ex_input = [ex['input'] for ex in ex_combo]\n",
    "                    ex_output = [ex['output'] for ex in ex_combo]\n",
    "\n",
    "                    # 데이터에 추가하면서 원래 예제의 개수도 포함\n",
    "                    self.data.append({\n",
    "                        'id': key,\n",
    "                        'input': task_input,\n",
    "                        'output': task_output,\n",
    "                        'ex_input': ex_input,\n",
    "                        'ex_output': ex_output,\n",
    "                        'num_original_examples': n_examples  # 원래 예제 개수 추가\n",
    "                    })\n",
    "\n",
    "        # 리스트를 데이터프레임으로 변환\n",
    "        self.df = pd.DataFrame(self.data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def pad_to_32x32(self, tensor):\n",
    "        if tensor.dim() == 2:\n",
    "            tensor = tensor.unsqueeze(0)\n",
    "        c, h, w = tensor.shape\n",
    "        pad_h = max(0, 32 - h)\n",
    "        pad_w = max(0, 32 - w)\n",
    "        \n",
    "        # 좌우 및 상하 패딩을 반반씩 나눠서 적용\n",
    "        padding = (pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2)\n",
    "        tensor = F.pad(tensor, padding, mode='constant', value=0)\n",
    "        \n",
    "        return tensor\n",
    "\n",
    "    def mapping_input(self, tensor):\n",
    "        mapping = {\n",
    "            1: random.randint(1, 10),\n",
    "            2: random.randint(11, 20),\n",
    "            3: random.randint(21, 30),\n",
    "            4: random.randint(31, 40),\n",
    "            5: random.randint(41, 50),\n",
    "            6: random.randint(51, 60),\n",
    "            7: random.randint(61, 70),\n",
    "            8: random.randint(71, 80),\n",
    "            9: random.randint(81, 90),\n",
    "            10: random.randint(91, 100)\n",
    "        }\n",
    "        temp_tensor = tensor.clone()\n",
    "        for k in mapping:\n",
    "            temp_tensor[temp_tensor == k] = -k  # 임시로 기존 값에 음수를 취해 중복을 피함\n",
    "\n",
    "        # 최종 매핑 적용\n",
    "        for k, v in mapping.items():\n",
    "            temp_tensor[temp_tensor == -k] = v\n",
    "        return temp_tensor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        task = self.df.iloc[idx]\n",
    "        \n",
    "        # task_input과 task_output 변환 및 패딩 추가\n",
    "        task_input = self.pad_to_32x32((torch.tensor(task['input'], dtype=torch.float32) + 1)) # [1, 32, 32]\n",
    "        task_output = self.pad_to_32x32((torch.tensor(task['output'], dtype=torch.float32) + 1)) # [1, 32, 32]\n",
    "        task_input = one_hot_encoding(task_input)\n",
    "        \n",
    "        # 입력 채널 차원 추가\n",
    "        if task_input.dim() == 2:\n",
    "            task_input = task_input.unsqueeze(0)  # [1, H, W]\n",
    "        if task_output.dim() == 2:\n",
    "            task_output = task_output.unsqueeze(0)  # [1, H, W]\n",
    "        \n",
    "        # 예제 입력과 출력 변환 및 패딩 추가\n",
    "        example_input = []\n",
    "        example_output = []\n",
    "        for ex_in, ex_out in zip(task['ex_input'], task['ex_output']):\n",
    "            ex_in_tensor = self.pad_to_32x32(torch.tensor(ex_in, dtype=torch.float32) + 1)\n",
    "            ex_out_tensor = self.pad_to_32x32(torch.tensor(ex_out, dtype=torch.float32) + 1)\n",
    "            ex_in_tensor = one_hot_encoding(ex_in_tensor)\n",
    "            ex_out_tensor = one_hot_encoding(ex_out_tensor)\n",
    "            \n",
    "            # 입력 채널 차원 추가\n",
    "            if ex_in_tensor.dim() == 2:\n",
    "                ex_in_tensor = ex_in_tensor.unsqueeze(0)  # [1, H, W]\n",
    "            if ex_out_tensor.dim() == 2:\n",
    "                ex_out_tensor = ex_out_tensor.unsqueeze(0)  # [1, H, W]\n",
    "            \n",
    "            example_input.append(ex_in_tensor)\n",
    "            example_output.append(ex_out_tensor)\n",
    "        \n",
    "        # 예제 입력과 출력을 채널 차원으로 결합\n",
    "        ex_inputs = torch.cat(example_input, dim=0)  # [n_examples * channels, H, W]\n",
    "        ex_outputs = torch.cat(example_output, dim=0)  # [n_examples * channels, H, W]\n",
    "        \n",
    "        return task_input, task_output, ex_inputs, ex_outputs\n",
    "\n",
    "# 사용 예제\n",
    "train_challenge = './kaggle/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "train_solution = \"./kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\"\n",
    "\n",
    "train_dataset = ARC_Dataset(train_challenge, train_solution)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "ti, to, ei, eo = next(iter(train_loader))\n",
    "print(ti.shape, to.shape, ei.shape, eo.shape)\n",
    "print(ti.dtype, to.dtype, ei.dtype, eo.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산 함수 (픽셀 단위와 이미지 단위)\n",
    "def calculate_accuracy(predictions, targets, ignore_index=0):\n",
    "    # 예측된 클래스 선택 (argmax 사용) -> 정수값으로 변환\n",
    "    pred_classes = predictions.argmax(dim=1)  # [batch_size, H, W]\n",
    "    \n",
    "    # 타겟 차원 맞추기 (타겟은 [batch_size, 1, H, W] 형태일 수 있으므로 squeeze)\n",
    "    targets = targets.squeeze(1)  # [batch_size, H, W]\n",
    "    \n",
    "    # 무시할 인덱스가 있는 경우 (ignore_index) 해당 픽셀을 계산에서 제외\n",
    "    if ignore_index is not None:\n",
    "        mask = (targets != ignore_index)\n",
    "    else:\n",
    "        mask = torch.ones_like(targets, dtype=torch.bool)\n",
    "    \n",
    "    # 픽셀 단위 정확도 계산\n",
    "    correct_pixels = (pred_classes == targets) & mask  # [batch_size, H, W]\n",
    "    correct_pixel_count = correct_pixels.sum().item()  # 맞은 픽셀 수\n",
    "    total_pixel_count = mask.sum().item()  # 유효한 전체 픽셀 수\n",
    "    \n",
    "    # 이미지 단위 정확도 계산 (모든 픽셀이 맞아야 해당 이미지를 정확히 예측한 것으로 간주)\n",
    "    correct_images = correct_pixels.view(targets.size(0), -1).all(dim=1)  # 각 이미지별로 모든 픽셀이 맞는지 확인\n",
    "    correct_image_count = correct_images.sum().item()  # 맞은 이미지 수\n",
    "    total_image_count = targets.size(0)  # 전체 이미지 수\n",
    "    \n",
    "    return correct_image_count, total_image_count, correct_pixel_count, total_pixel_count\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def visualize_predictions(inputs, targets, predictions, condition):\n",
    "    if condition:\n",
    "        # 입력 이미지와 예측 결과를 CPU로 이동\n",
    "        inputs = inputs.cpu().numpy()\n",
    "        targets = targets.cpu().numpy()\n",
    "        predictions = predictions.detach().cpu().numpy()  # detach()로 그래디언트 추적 중단\n",
    "\n",
    "        # 시각화할 샘플의 수 (최대 3개의 샘플)\n",
    "        num_images = min(3, inputs.shape[0])\n",
    "\n",
    "        # 컬러 맵 정의 (0~10 값을 위한 11개의 색상)\n",
    "        color_list = ['black', 'blue', 'red', 'green', 'yellow', 'purple', \n",
    "                      'orange', 'pink', 'gray', 'brown', 'cyan']\n",
    "        cmap = ListedColormap(color_list)\n",
    "\n",
    "        # 시각화를 위한 플롯 생성 (3개의 입력, 타겟, 예측 이미지를 각각 표시)\n",
    "        fig, axes = plt.subplots(3, num_images, figsize=(6 * num_images, 12))  # 이전보다 더 큰 플롯 크기 설정\n",
    "\n",
    "\n",
    "        for i in range(num_images):\n",
    "            # 입력 이미지 처리\n",
    "            input_image = inputs.argmax(axis=1)[i]  # shape: (H, W)\n",
    "            if input_image.ndim == 3 and input_image.shape[0] == 1:\n",
    "                input_image = input_image.squeeze(0)  # 단일 채널 이미지 (H, W)\n",
    "\n",
    "            # 타겟 이미지 처리\n",
    "            target_image = targets[i].squeeze(0)  # shape: (H, W)\n",
    "            target_image = target_image.astype(int)\n",
    "\n",
    "            # 예측 이미지 처리\n",
    "            prediction_image = predictions.argmax(axis=1)[i]  # shape: (H, W)\n",
    "            prediction_image = prediction_image.astype(int)\n",
    "\n",
    "            # 입력 이미지 표시\n",
    "            axes[0, i].imshow(input_image, cmap=cmap, vmin=0, vmax=10)\n",
    "            axes[0, i].set_title(f'Input Image {i+1}')\n",
    "            axes[0, i].axis('off')\n",
    "\n",
    "            # 타겟 이미지 표시\n",
    "            axes[1, i].imshow(target_image, cmap=cmap, vmin=0, vmax=10)\n",
    "            axes[1, i].set_title(f'Ground Truth {i+1}')\n",
    "            axes[1, i].axis('off')\n",
    "\n",
    "            # 예측 이미지 표시\n",
    "            axes[2, i].imshow(prediction_image, cmap=cmap, vmin=0, vmax=10)\n",
    "            axes[2, i].set_title(f'Prediction {i+1}')\n",
    "            axes[2, i].axis('off')\n",
    "\n",
    "        # 범례를 플롯 내에 표시\n",
    "        patches = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color_list[j], markersize=10, label=str(j)) for j in range(11)]\n",
    "        plt.legend(handles=patches, bbox_to_anchor=(1.05, 0.5), loc='center left', borderaxespad=0.)\n",
    "\n",
    "        plt.tight_layout()  # 레이아웃을 자동으로 조정\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 단위 정확도: 2/4\n",
      "픽셀 단위 정확도: 2255/4096\n"
     ]
    }
   ],
   "source": [
    "# 예시 테스트 코드\n",
    "batch_size = 4\n",
    "height = 32\n",
    "width = 32\n",
    "num_classes = 11  # 11개의 클래스를 가정\n",
    "\n",
    "# 임의의 예측값 생성 (logits 형태로, [batch_size, num_classes, H, W]의 크기)\n",
    "predictions = torch.randn(batch_size, num_classes, height, width)\n",
    "\n",
    "# 임의의 타겟값 생성 (정수값으로, [batch_size, 1, H, W]의 크기)\n",
    "targets = torch.randint(0, num_classes, (batch_size, 1, height, width))\n",
    "\n",
    "# 첫 번째와 두 번째 샘플의 예측값을 타겟값과 완전히 동일하게 설정\n",
    "for i in range(2):  # 첫 번째와 두 번째 샘플을 타겟과 맞춤\n",
    "    predictions[i] = torch.zeros_like(predictions[i])  # logits을 0으로 초기화\n",
    "    for c in range(num_classes):\n",
    "        predictions[i, c] = (targets[i].squeeze(0) == c).float() * 1000.0  # 타겟과 동일하게 맞춤\n",
    "\n",
    "# 정확도 계산 함수 호출\n",
    "correct_samples, total_samples, correct_pixels, total_pixels = calculate_accuracy(predictions, targets, ignore_index=None)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"이미지 단위 정확도: {correct_samples}/{total_samples}\")\n",
    "print(f\"픽셀 단위 정확도: {correct_pixels}/{total_pixels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 이미지 단위 정확도: 50.00%\n",
      "전체 픽셀 단위 정확도: 51.56%\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "# # 배치별로 처리되는 정확도 계산 함수 (앞서 작성한 함수)\n",
    "# def calculate_accuracy(predictions, targets, ignore_index=0):\n",
    "#     pred_classes = predictions.argmax(dim=1).long()  # [batch_size, H, W]\n",
    "#     targets = targets.squeeze(1)  # [batch_size, H, W]\n",
    "    \n",
    "#     if ignore_index is not None:\n",
    "#         mask = (targets != ignore_index)\n",
    "#     else:\n",
    "#         mask = torch.ones_like(targets, dtype=torch.bool)\n",
    "    \n",
    "#     correct_pixels = (pred_classes == targets) & mask  # [batch_size, H, W]\n",
    "#     correct_pixel_count = correct_pixels.sum().item()  # 맞은 픽셀 수\n",
    "#     total_pixel_count = mask.sum().item()  # 유효한 전체 픽셀 수\n",
    "    \n",
    "#     correct_images = correct_pixels.view(targets.size(0), -1).all(dim=1)  # 각 이미지별로 모든 픽셀이 맞는지 확인\n",
    "#     correct_image_count = correct_images.sum().item()  # 맞은 이미지 수\n",
    "#     total_image_count = targets.size(0)  # 전체 이미지 수\n",
    "    \n",
    "#     return correct_image_count, total_image_count, correct_pixel_count, total_pixel_count\n",
    "\n",
    "# # 누적된 정확도를 계산하고 테스트하는 함수\n",
    "# def test_batch_accuracy():\n",
    "#     batch_size = 4\n",
    "#     height = 32\n",
    "#     width = 32\n",
    "#     num_classes = 11\n",
    "#     num_batches = 3  # 3개의 배치 처리 가정\n",
    "\n",
    "#     total_correct_samples = 0\n",
    "#     total_samples = 0\n",
    "#     total_correct_pixels = 0\n",
    "#     total_pixels = 0\n",
    "\n",
    "#     for batch_idx in range(num_batches):\n",
    "#         # 예측값과 타겟값 생성 (여기서는 간단하게 무작위로 생성)\n",
    "#         predictions = torch.randn(batch_size, num_classes, height, width)\n",
    "#         targets = torch.randint(0, num_classes, (batch_size, 1, height, width))\n",
    "\n",
    "#         # 첫 번째 배치는 완전히 정확하게 설정\n",
    "#         if batch_idx == 0:\n",
    "#             for i in range(batch_size):\n",
    "#                 predictions[i] = torch.zeros_like(predictions[i])\n",
    "#                 for c in range(num_classes):\n",
    "#                     predictions[i, c] = (targets[i].squeeze(0) == c).float() * 1000.0\n",
    "\n",
    "#         # 두 번째 배치는 절반만 정확하게 설정\n",
    "#         elif batch_idx == 1:\n",
    "#             for i in range(batch_size // 2):  # 첫 번째 절반만 정확하게\n",
    "#                 predictions[i] = torch.zeros_like(predictions[i])\n",
    "#                 for c in range(num_classes):\n",
    "#                     predictions[i, c] = (targets[i].squeeze(0) == c).float() * 1000.0\n",
    "        \n",
    "#         # 세 번째 배치는 전부 틀리게 설정\n",
    "#         else:\n",
    "#             predictions = torch.zeros_like(predictions)\n",
    "#             targets = torch.ones(batch_size, 1, height, width).long() * (num_classes - 1)\n",
    "\n",
    "#         # 배치별 정확도 계산\n",
    "#         correct_samples, batch_total_samples, correct_pixels, batch_total_pixels = calculate_accuracy(predictions, targets, ignore_index=None)\n",
    "        \n",
    "#         # 누적 정확도 계산\n",
    "#         total_correct_samples += correct_samples\n",
    "#         total_samples += batch_total_samples\n",
    "#         total_correct_pixels += correct_pixels\n",
    "#         total_pixels += batch_total_pixels\n",
    "\n",
    "#     # 전체 배치에서 누적된 정확도 계산\n",
    "#     avg_sample_accuracy = 100. * float(total_correct_samples) / float(total_samples)\n",
    "#     avg_pixel_accuracy = 100. * float(total_correct_pixels) / float(total_pixels)\n",
    "\n",
    "#     print(f\"전체 이미지 단위 정확도: {avg_sample_accuracy:.2f}%\")\n",
    "#     print(f\"전체 픽셀 단위 정확도: {avg_pixel_accuracy:.2f}%\")\n",
    "\n",
    "# # 테스트 함수 실행\n",
    "# test_batch_accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] Complete | Average Loss: 0.557622 | Training Sample Accuracy: 0.00% | Training Pixel Accuracy: 15.20%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  15%|█▌        | 12/78 [00:03<00:24,  2.69it/s, loss=0.6864]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_challenge = './kaggle/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "train_solution = \"./kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\"\n",
    "eval_challenge = \"./kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json\"\n",
    "eval_solution = \"./kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\"\n",
    "\n",
    "train_args = {\n",
    "    'challenges': train_challenge,\n",
    "    'solution': train_solution,\n",
    "    'num_classes': 11,\n",
    "    'batch_size': 48,\n",
    "    'epochs': 1000,\n",
    "    'learning_rate': 0.001,\n",
    "}\n",
    "\n",
    "model_args = {\n",
    "    'dims': (32,64,128),\n",
    "    'heads': 4,\n",
    "    'ff_expansion': 4,\n",
    "    'reduction_ratio': (4,2,2),\n",
    "    'num_layers': (2,3,4),\n",
    "    'channels': 11,\n",
    "    'num_classes': 11,\n",
    "    'kernel_stride_paddings': ((3, 1, 1),(3, 2, 1),(3, 2, 1))\n",
    "    }\n",
    "\n",
    "def criterion(y_pred, y):\n",
    "    y = y.long().squeeze(1)\n",
    "    weight = torch.ones(train_args['num_classes']).to(y.device)\n",
    "    weight[0] = 0.04\n",
    "    weight[1] = 0.8\n",
    "    ce = F.cross_entropy(y_pred, y, weight=weight) \n",
    "    return ce\n",
    "\n",
    "\n",
    "# CUDA 사용 가능 여부 확인\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else device\n",
    "print(f'Using {device} device')\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "train_dataset = ARC_Dataset(train_challenge, train_solution)\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_args['batch_size'], shuffle=True)\n",
    "\n",
    "eval_dataset = ARC_Dataset(eval_challenge, eval_solution)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=train_args['batch_size'], shuffle=False)\n",
    "\n",
    "# 모델 정의\n",
    "model = ARC_Net(**model_args).to(device)\n",
    "\n",
    "# 옵티마이저 정의\n",
    "optimizer = optim.AdamW(model.parameters(), lr=train_args['learning_rate'])\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct_samples = 0\n",
    "    total_samples = 0\n",
    "    total_correct_pixels = 0\n",
    "    total_pixels = 0\n",
    "\n",
    "    last_task_inputs = None\n",
    "    last_task_outputs = None\n",
    "    last_output = None\n",
    "\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch+1}/{train_args[\"epochs\"]}', leave=False)\n",
    "\n",
    "    for batch_idx, (task_inputs, task_outputs, ex_inputs, ex_outputs) in progress_bar:\n",
    "        task_inputs = task_inputs.to(device, non_blocking=True)\n",
    "        task_outputs = task_outputs.to(device, non_blocking=True)\n",
    "        ex_inputs = ex_inputs.to(device, non_blocking=True)\n",
    "        ex_outputs = ex_outputs.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(task_inputs, ex_inputs, ex_outputs)\n",
    "\n",
    "        # 손실 함수 계산\n",
    "        loss = criterion(output, task_outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        correct_samples, batch_total_samples, correct_pixels, batch_total_pixels = calculate_accuracy(output, task_outputs, ignore_index=0)\n",
    "        total_correct_samples += correct_samples\n",
    "        total_samples += batch_total_samples\n",
    "        total_correct_pixels += correct_pixels\n",
    "        total_pixels += batch_total_pixels\n",
    "\n",
    "        # 마지막 배치의 데이터 저장 (clone 제거)\n",
    "        last_task_inputs = task_inputs.detach()\n",
    "        last_task_outputs = task_outputs.detach()\n",
    "        last_output = output.detach()\n",
    "        \n",
    "        # 프로그레스 바 업데이트\n",
    "        progress_bar.set_postfix(loss=f'{loss.item():.4f}')\n",
    "    \n",
    "    # 에포크가 끝난 후\n",
    "    avg_sample_accuracy = 100. * float(total_correct_samples) / float(total_samples)\n",
    "    avg_pixel_accuracy = 100. * float(total_correct_pixels) / float(total_pixels)\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{train_args[\"epochs\"]}] Complete | Average Loss: {avg_loss:.6f} | Training Sample Accuracy: {avg_sample_accuracy:.4f}% | Training Pixel Accuracy: {avg_pixel_accuracy:.2f}%')\n",
    "\n",
    "    # 에포크가 10의 배수일 때만 시각화 수행\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        visualize_predictions(last_task_inputs, last_task_outputs, last_output, condition=True)\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct_samples = 0\n",
    "    total_samples = 0\n",
    "    total_correct_pixels = 0\n",
    "    total_pixels = 0\n",
    "\n",
    "    last_task_inputs = None\n",
    "    last_task_outputs = None\n",
    "    last_output = None\n",
    "\n",
    "    progress_bar = tqdm(enumerate(eval_loader), total=len(eval_loader), desc='Testing', leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (task_inputs, task_outputs, ex_inputs, ex_outputs) in progress_bar:\n",
    "            task_inputs = task_inputs.to(device, non_blocking=True)\n",
    "            task_outputs = task_outputs.to(device, non_blocking=True)\n",
    "            ex_inputs = ex_inputs.to(device, non_blocking=True)\n",
    "            ex_outputs = ex_outputs.to(device, non_blocking=True)\n",
    "\n",
    "            output = model(task_inputs, ex_inputs, ex_outputs)\n",
    "\n",
    "            # 손실 함수 계산\n",
    "            loss = criterion(output, task_outputs)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 정확도 계산\n",
    "            correct_samples, batch_total_samples, correct_pixels, batch_total_pixels = calculate_accuracy(output, task_outputs, ignore_index=0)\n",
    "            total_correct_samples += correct_samples\n",
    "            total_samples += batch_total_samples\n",
    "            total_correct_pixels += correct_pixels\n",
    "            total_pixels += batch_total_pixels\n",
    "\n",
    "            # 마지막 배치의 데이터 저장 (clone 제거)\n",
    "            last_task_inputs = task_inputs.detach()\n",
    "            last_task_outputs = task_outputs.detach()\n",
    "            last_output = output.detach()\n",
    "            \n",
    "            # 프로그레스 바 업데이트\n",
    "            progress_bar.set_postfix(loss=f'{loss.item():.4f}')\n",
    "    \n",
    "    avg_sample_accuracy = 100. * float(total_correct_samples) / float(total_samples)\n",
    "    avg_pixel_accuracy = 100. * float(total_correct_pixels) / float(total_pixels)\n",
    "    avg_loss = total_loss / len(eval_loader)\n",
    "\n",
    "    print(f'Test Average Loss: {avg_loss:.6f} | Test Sample Accuracy: {avg_sample_accuracy:.4f}% | Test Pixel Accuracy: {avg_pixel_accuracy:.2f}%')\n",
    "\n",
    "    # 에포크가 10의 배수일 때만 시각화 수행\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        visualize_predictions(last_task_inputs, last_task_outputs, last_output, condition=True)\n",
    "\n",
    "# 학습 실행\n",
    "for epoch in range(train_args['epochs']):  \n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
