{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader_sw import ARC_Dataset\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))\n",
    "        self.b = nn.Parameter(torch.zeros(1, dim, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        std = torch.var(x, dim=1, unbiased=False, keepdim=True).sqrt()\n",
    "        mean = torch.mean(x, dim=1, keepdim=True)\n",
    "        return (x - mean) / (std + self.eps) * self.g + self.b\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(self.norm(x))\n",
    "\n",
    "class DsConv2d(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, kernel_size, padding, stride = 1, bias = True):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_in, kernel_size = kernel_size, padding = padding, groups = dim_in, stride = stride, bias=bias),\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size = 1, bias = bias)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "## 디코더\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                lse_pool = logsumexp_2d(x)\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return x * scale\n",
    "\n",
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = F.sigmoid(x_out) # broadcasting\n",
    "        return x * scale\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate = SpatialGate()\n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.SpatialGate(x_out)\n",
    "        return x_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from einops import rearrange\n",
    "from math import sqrt\n",
    "\n",
    "def cast_tuple(val, depth):\n",
    "    return val if isinstance(val, tuple) else (val,) * depth\n",
    "\n",
    "class EfficientSelfAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        heads,\n",
    "        reduction_ratio\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.scale = (dim // heads) ** -0.5\n",
    "        self.heads = heads\n",
    "\n",
    "        self.to_q = nn.Conv2d(dim, dim, 1, bias = False)\n",
    "        self.to_kv = nn.Conv2d(dim, dim * 2, reduction_ratio, stride = reduction_ratio, bias = False)\n",
    "        self.to_out = nn.Conv2d(dim, dim, 1, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, w = x.shape[-2:]\n",
    "        heads = self.heads\n",
    "\n",
    "        q, k, v = (self.to_q(x), *self.to_kv(x).chunk(2, dim = 1))\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b (h c) x y -> (b h) (x y) c', h = heads), (q, k, v))\n",
    "\n",
    "        sim = einsum('b i d, b j d -> b i j', q, k) * self.scale\n",
    "        attn = sim.softmax(dim = -1)\n",
    "\n",
    "        out = einsum('b i j, b j d -> b i d', attn, v)\n",
    "        out = rearrange(out, '(b h) (x y) c -> b (h c) x y', h = heads, x = h, y = w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class MixFeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        expansion_factor\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = dim * expansion_factor\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(dim, hidden_dim, 1),\n",
    "            DsConv2d(hidden_dim, hidden_dim, 3, padding = 1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(hidden_dim, dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "## 컨볼루션 임베딩\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, dim_in,dim_out, kernel_size, stride, padding):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Conv2d(dim_in, \n",
    "                                   dim_out, \n",
    "                                   kernel_size=kernel_size, \n",
    "                                   stride=stride, \n",
    "                                   padding=padding)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "    \n",
    "'''\n",
    "5. MiT (Mixer Transformer)\n",
    "이미지를 여러 스테이지로 처리합니다. 각 스테이지는 이미지를 패치로 나누고, 패치를 임베딩한 후, 여러 개의 Transformer 레이어를 적용합니다.\n",
    "이 과정은 이미지의 다양한 해상도에서 특징을 추출합니다. \n",
    "'''    \n",
    "class MiT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        channels,\n",
    "        dims,\n",
    "        heads,\n",
    "        ff_expansion,\n",
    "        reduction_ratio,\n",
    "        num_layers,\n",
    "        stage_kernel_stride_pad = ((7, 4, 3),  \n",
    "                                   (3, 2, 1), \n",
    "                                   (3, 2, 1), \n",
    "                                   (3, 2, 1))\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        dims = (channels, *dims)\n",
    "        dim_pairs = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        self.stages = nn.ModuleList([])\n",
    "\n",
    "        for (dim_in, dim_out), (kernel, stride, padding), num_layers, ff_expansion, heads, reduction_ratio in zip(\n",
    "            dim_pairs, stage_kernel_stride_pad, num_layers, ff_expansion, heads, reduction_ratio):\n",
    "            #여기서 너비와 높이가 같은 정사각형 패치를 사용합니다.\n",
    "            get_overlap_patches = nn.Unfold(kernel, stride = stride, padding = padding)\n",
    "            overlap_patch_embed = nn.Conv2d(dim_in * kernel ** 2, dim_out, 1)\n",
    "\n",
    "            layers = nn.ModuleList([])\n",
    "\n",
    "            for _ in range(num_layers):\n",
    "                layers.append(nn.ModuleList([\n",
    "                    PreNorm(dim_out, EfficientSelfAttention(dim = dim_out, heads = heads, reduction_ratio = reduction_ratio)),\n",
    "                    PreNorm(dim_out, MixFeedForward(dim = dim_out, expansion_factor = ff_expansion)),\n",
    "                ]))\n",
    "\n",
    "            self.stages.append(nn.ModuleList([\n",
    "                get_overlap_patches,\n",
    "                overlap_patch_embed,\n",
    "                layers\n",
    "            ]))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        return_layer_outputs = False\n",
    "    ):\n",
    "        h, w = x.shape[-2:]\n",
    "        \n",
    "        \n",
    "        layer_outputs = []\n",
    "        for (get_overlap_patches, overlap_embed, layers) in self.stages:\n",
    "            x = get_overlap_patches(x)\n",
    "            \n",
    "            num_patches = x.shape[-1]\n",
    "            ratio = int(sqrt((h * w) / num_patches))\n",
    "            \n",
    "            x = rearrange(x, 'b c (h w) -> b c h w', h = h // ratio)\n",
    "\n",
    "            x = overlap_embed(x)\n",
    "            for (attn, ff) in layers:\n",
    "                x = attn(x) + x\n",
    "                x = ff(x) + x\n",
    "\n",
    "            layer_outputs.append(x)\n",
    "\n",
    "        ret = x if not return_layer_outputs else layer_outputs\n",
    "        return ret\n",
    "    \n",
    "class Head(nn.Module):\n",
    "    def __init__(self, input_dim = 256 ,dim=128, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(input_dim , (input_dim//3)*2, kernel_size=1),  \n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d((input_dim//3)*2 , input_dim//3, kernel_size=1),  \n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(dim, num_classes, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "'''\n",
    "6. Segformer\n",
    "MiT를 통해 추출된 여러 스케일의 특징을 결합하고, 최종적으로 세그멘테이션 맵을 생성합니다.\n",
    "각 스테이지의 출력을 디코더 차원으로 매핑하고, 업샘플링하여 동일한 해상도로 만든 후, 이를 결합합니다.\n",
    "결합된 특징 맵을 사용하여 최종 세그멘테이션 맵을 생성합니다.\n",
    "'''\n",
    "class ARC_Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dims=(32, 64, 160, 256),\n",
    "        heads=(1, 2, 5, 8),\n",
    "        ff_expansion=(8, 8, 4, 4),\n",
    "        reduction_ratio=(8, 4, 2, 1),\n",
    "        num_layers=2,\n",
    "        channels=11,\n",
    "        num_classes=11,\n",
    "        kernel_stride_paddings = ((1, 1, 0),(3, 2, 1), (3, 2, 1), (3, 2, 1))\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        decoder_dim = dims[-1]\n",
    "        \n",
    "        dims, heads, ff_expansion, reduction_ratio, num_layers = map(\n",
    "            partial(cast_tuple, depth=len(kernel_stride_paddings)), (dims, heads, ff_expansion, reduction_ratio, num_layers))\n",
    "\n",
    "        \n",
    "        self.mit = MiT(\n",
    "            channels=channels,\n",
    "            dims=dims,\n",
    "            heads=heads,\n",
    "            ff_expansion=ff_expansion,\n",
    "            reduction_ratio=reduction_ratio,\n",
    "            num_layers=num_layers,\n",
    "            stage_kernel_stride_pad=kernel_stride_paddings\n",
    "        )\n",
    "\n",
    "        self.to_fused = nn.ModuleList([nn.Sequential(\n",
    "            nn.Conv2d(dim, decoder_dim, 1),\n",
    "            nn.Upsample(scale_factor=2 ** i)\n",
    "        ) for i, dim in enumerate(dims)])\n",
    "\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.cbam = CBAM(gate_channels = decoder_dim * len(kernel_stride_paddings) * 2)  \n",
    "        \n",
    "        self.cbam2 = CBAM(gate_channels = decoder_dim * len(kernel_stride_paddings) * 2)\n",
    "        \n",
    "        self.reduce = nn.Conv2d(decoder_dim * len(dims) * 2, decoder_dim * len(dims), 1)        \n",
    "        \n",
    "        self.to_segmentation = Head(decoder_dim*len(dims) * 3, decoder_dim*len(dims) , num_classes)\n",
    "        \n",
    "    def _fusion(self, x):\n",
    "        x = self.mit(x, return_layer_outputs=True)\n",
    "        # 드랍아웃 \n",
    "        x = [self.gelu(x) for x in x]\n",
    "        x = [self.dropout(x) for x in x]\n",
    "        fused = []\n",
    "        for output, to_fused in zip(x, self.to_fused):\n",
    "            x = to_fused(output)  # Conv2d 적용\n",
    "            # 업샘플링하여 공간 크기를 맞춥니다.\n",
    "            fused.append(x)\n",
    "        fused = torch.cat(fused, dim=1)\n",
    "        \n",
    "        return fused    \n",
    "    \n",
    "    def forward(self, x, ex_inputs, ex_outputs):\n",
    "        x = self._fusion(x) # [b,1,H,W] -> [b,dim_0,H,W],...,[b,dim_n, H//(n+1), W//(n+1)] \n",
    "                            # -> [b,dim_n, H, W],...,[b,dim_n, H, W] -> [b, dim_n * 2, H, W]\n",
    "                            # [b, 256, 32, 32]\n",
    "                            \n",
    "        # 예제 입력과 출력을 채널 차원으로 분할\n",
    "        n_examples = ex_inputs.size(1)//self.channels  # n_examples * channels (여기서는 3)\n",
    "        \n",
    "        # 예제 수만큼 반복하면서 예제 입력과 출력을 처리\n",
    "        fused = []\n",
    "        for i in range(n_examples):\n",
    "            ex_i = ex_inputs[:, i*self.channels:(i+1)*self.channels, :, :]  # [batch_size, 1, H, W]\n",
    "            ex_o = ex_outputs[:, i*self.channels:(i+1)*self.channels, :, :]  # [batch_size, 1, H, W]\n",
    "            \n",
    "            ex_i = self._fusion(ex_i)\n",
    "            ex_o = self._fusion(ex_o)\n",
    "            \n",
    "            ex_f = torch.cat([ex_i, ex_o], dim=1)\n",
    "            ex_f = self.cbam(ex_f)\n",
    "            ex_f = self.reduce(ex_f)\n",
    "            fused.append(ex_f)\n",
    "        \n",
    "        for i, ex_f in enumerate(fused):\n",
    "            ex_f = torch.cat([x, ex_f], dim=1)\n",
    "            ex_f = self.cbam2(ex_f)\n",
    "            ex_f = self.reduce(ex_f)\n",
    "            fused[i] = ex_f\n",
    "        \n",
    "        fused = torch.cat(fused, dim=1)\n",
    "        output = self.to_segmentation(fused)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 및 출력\n",
    "model_args = {\n",
    "    'dims': (16,32, 64, 128),\n",
    "    'heads': 4,\n",
    "    'ff_expansion': 4,\n",
    "    'reduction_ratio': (4,2,2,2),\n",
    "    'num_layers': (1,2,3,4),\n",
    "    'channels': 11,\n",
    "    'num_classes': 11,\n",
    "    'kernel_stride_paddings': ((3, 1, 1),(3, 2, 1),(3, 2, 1),(3, 2, 1))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dims, heads, ff_expansion, reduction_ratio, num_layers = map(\n",
    "#             partial(cast_tuple, depth=4), (model_args['dims'], \n",
    "#                                            model_args['heads'], \n",
    "#                                            model_args['ff_expansion'], \n",
    "#                                            model_args['reduction_ratio'], \n",
    "#                                            model_args['num_layers']))\n",
    "# mit = MiT(\n",
    "#         dims=dims,\n",
    "#         heads=heads,\n",
    "#         ff_expansion=ff_expansion,\n",
    "#         reduction_ratio=reduction_ratio,\n",
    "#         num_layers=num_layers,\n",
    "#         channels=model_args['channels'],\n",
    "#         stage_kernel_stride_pad=model_args['kernel_stride_paddings'],\n",
    "        \n",
    "#           )\n",
    "# x = torch.randn(10, 1, 30, 30)\n",
    "\n",
    "# print(\"Input shape:\", x.shape)\n",
    "# x = mit(x,return_layer_outputs = True)\n",
    "\n",
    "# print(\"Output shape:\", x[0].shape)\n",
    "# print(\"Output shape:\", x[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor = torch.randn(10, 1, 30, 30)\n",
    "# i = 0\n",
    "# h = tensor[:, i:i+11, :, :]\n",
    "# h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuse = [torch.randn(10, 256, 32, 32), torch.randn(10, 256, 32, 32), torch.randn(10, 256, 32, 32)]\n",
    "\n",
    "# x= torch.randn(10, 256, 32, 32)\n",
    "# for i , ex in enumerate(fuse) :\n",
    "#     print(\"fuse shape:\", ex.shape)\n",
    "#     ex = torch.cat([ex, x], dim=1)\n",
    "#     print(\"fuse shape:\", ex.shape)\n",
    "#     fuse[i] = ex\n",
    "#     print(\"fuse shape:\", fuse[i].shape)\n",
    "#     print(\"==================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "torch.Size([10, 11, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# CUDA 사용 가능 여부 확인\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else device\n",
    "print(f'Using {device} device')\n",
    "model = ARC_Net(**model_args).to(device)\n",
    "# 입력 텐서 생성\n",
    "x = torch.randn(10, 11, 32, 32).to(device)\n",
    "e_i, e_o = torch.randn(10, 33, 32, 32).to(device), torch.randn(10, 33, 32, 32).to(device)\n",
    "print(model(x,e_i,e_o).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type:depth-idx)                                                 Output Shape              Param #\n",
       "========================================================================================================================\n",
       "ARC_Net                                                                [1, 11, 32, 32]           --\n",
       "├─MiT: 1-1                                                             [1, 16, 32, 32]           --\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-2                                                            [1, 16, 32, 32]           --\n",
       "├─GELU: 1-3                                                            [1, 32, 16, 16]           --\n",
       "├─GELU: 1-4                                                            [1, 64, 8, 8]             --\n",
       "├─GELU: 1-5                                                            [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-6                                                         [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-7                                                         [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-8                                                         [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-9                                                         [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-2                                                 [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-5                                                [1, 128, 32, 32]          2,176\n",
       "│    │    └─Upsample: 3-6                                              [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-3                                                 [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-7                                                [1, 128, 16, 16]          4,224\n",
       "│    │    └─Upsample: 3-8                                              [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-4                                                 [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-9                                                [1, 128, 8, 8]            8,320\n",
       "│    │    └─Upsample: 3-10                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-5                                                 [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-11                                               [1, 128, 4, 4]            16,512\n",
       "│    │    └─Upsample: 3-12                                             [1, 128, 32, 32]          --\n",
       "├─MiT: 1-11                                                            [1, 16, 32, 32]           (recursive)\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-12                                                           [1, 16, 32, 32]           --\n",
       "├─GELU: 1-13                                                           [1, 32, 16, 16]           --\n",
       "├─GELU: 1-14                                                           [1, 64, 8, 8]             --\n",
       "├─GELU: 1-15                                                           [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-16                                                        [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-17                                                        [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-18                                                        [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-19                                                        [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-7                                                 [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-17                                               [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Upsample: 3-18                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-8                                                 [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-19                                               [1, 128, 16, 16]          (recursive)\n",
       "│    │    └─Upsample: 3-20                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-9                                                 [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-21                                               [1, 128, 8, 8]            (recursive)\n",
       "│    │    └─Upsample: 3-22                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-10                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-23                                               [1, 128, 4, 4]            (recursive)\n",
       "│    │    └─Upsample: 3-24                                             [1, 128, 32, 32]          --\n",
       "├─MiT: 1-21                                                            [1, 16, 32, 32]           (recursive)\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-22                                                           [1, 16, 32, 32]           --\n",
       "├─GELU: 1-23                                                           [1, 32, 16, 16]           --\n",
       "├─GELU: 1-24                                                           [1, 64, 8, 8]             --\n",
       "├─GELU: 1-25                                                           [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-26                                                        [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-27                                                        [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-28                                                        [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-29                                                        [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-12                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-29                                               [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Upsample: 3-30                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-13                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-31                                               [1, 128, 16, 16]          (recursive)\n",
       "│    │    └─Upsample: 3-32                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-14                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-33                                               [1, 128, 8, 8]            (recursive)\n",
       "│    │    └─Upsample: 3-34                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-15                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-35                                               [1, 128, 4, 4]            (recursive)\n",
       "│    │    └─Upsample: 3-36                                             [1, 128, 32, 32]          --\n",
       "├─CBAM: 1-31                                                           [1, 1024, 32, 32]         --\n",
       "│    └─ChannelGate: 2-16                                               [1, 1024, 32, 32]         --\n",
       "│    │    └─Sequential: 3-37                                           [1, 1024]                 132,160\n",
       "│    │    └─Sequential: 3-38                                           [1, 1024]                 (recursive)\n",
       "│    └─SpatialGate: 2-17                                               [1, 1024, 32, 32]         --\n",
       "│    │    └─ChannelPool: 3-39                                          [1, 2, 32, 32]            --\n",
       "│    │    └─BasicConv: 3-40                                            [1, 1, 32, 32]            100\n",
       "├─Conv2d: 1-32                                                         [1, 512, 32, 32]          524,800\n",
       "├─MiT: 1-33                                                            [1, 16, 32, 32]           (recursive)\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-34                                                           [1, 16, 32, 32]           --\n",
       "├─GELU: 1-35                                                           [1, 32, 16, 16]           --\n",
       "├─GELU: 1-36                                                           [1, 64, 8, 8]             --\n",
       "├─GELU: 1-37                                                           [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-38                                                        [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-39                                                        [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-40                                                        [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-41                                                        [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-19                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-45                                               [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Upsample: 3-46                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-20                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-47                                               [1, 128, 16, 16]          (recursive)\n",
       "│    │    └─Upsample: 3-48                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-21                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-49                                               [1, 128, 8, 8]            (recursive)\n",
       "│    │    └─Upsample: 3-50                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-22                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-51                                               [1, 128, 4, 4]            (recursive)\n",
       "│    │    └─Upsample: 3-52                                             [1, 128, 32, 32]          --\n",
       "├─MiT: 1-43                                                            [1, 16, 32, 32]           (recursive)\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-44                                                           [1, 16, 32, 32]           --\n",
       "├─GELU: 1-45                                                           [1, 32, 16, 16]           --\n",
       "├─GELU: 1-46                                                           [1, 64, 8, 8]             --\n",
       "├─GELU: 1-47                                                           [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-48                                                        [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-49                                                        [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-50                                                        [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-51                                                        [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-24                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-57                                               [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Upsample: 3-58                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-25                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-59                                               [1, 128, 16, 16]          (recursive)\n",
       "│    │    └─Upsample: 3-60                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-26                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-61                                               [1, 128, 8, 8]            (recursive)\n",
       "│    │    └─Upsample: 3-62                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-27                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-63                                               [1, 128, 4, 4]            (recursive)\n",
       "│    │    └─Upsample: 3-64                                             [1, 128, 32, 32]          --\n",
       "├─CBAM: 1-53                                                           [1, 1024, 32, 32]         (recursive)\n",
       "│    └─ChannelGate: 2-28                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─Sequential: 3-65                                           [1, 1024]                 (recursive)\n",
       "│    │    └─Sequential: 3-66                                           [1, 1024]                 (recursive)\n",
       "│    └─SpatialGate: 2-29                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─ChannelPool: 3-67                                          [1, 2, 32, 32]            --\n",
       "│    │    └─BasicConv: 3-68                                            [1, 1, 32, 32]            (recursive)\n",
       "├─Conv2d: 1-54                                                         [1, 512, 32, 32]          (recursive)\n",
       "├─MiT: 1-55                                                            [1, 16, 32, 32]           (recursive)\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-56                                                           [1, 16, 32, 32]           --\n",
       "├─GELU: 1-57                                                           [1, 32, 16, 16]           --\n",
       "├─GELU: 1-58                                                           [1, 64, 8, 8]             --\n",
       "├─GELU: 1-59                                                           [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-60                                                        [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-61                                                        [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-62                                                        [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-63                                                        [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-31                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-73                                               [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Upsample: 3-74                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-32                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-75                                               [1, 128, 16, 16]          (recursive)\n",
       "│    │    └─Upsample: 3-76                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-33                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-77                                               [1, 128, 8, 8]            (recursive)\n",
       "│    │    └─Upsample: 3-78                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-34                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-79                                               [1, 128, 4, 4]            (recursive)\n",
       "│    │    └─Upsample: 3-80                                             [1, 128, 32, 32]          --\n",
       "├─MiT: 1-65                                                            [1, 16, 32, 32]           (recursive)\n",
       "│    └─ModuleList: 2-35                                                --                        (recursive)\n",
       "│    │    └─ModuleList: 3-81                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-82                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-83                                           --                        (recursive)\n",
       "│    │    └─ModuleList: 3-84                                           --                        (recursive)\n",
       "├─GELU: 1-66                                                           [1, 16, 32, 32]           --\n",
       "├─GELU: 1-67                                                           [1, 32, 16, 16]           --\n",
       "├─GELU: 1-68                                                           [1, 64, 8, 8]             --\n",
       "├─GELU: 1-69                                                           [1, 128, 4, 4]            --\n",
       "├─Dropout: 1-70                                                        [1, 16, 32, 32]           --\n",
       "├─Dropout: 1-71                                                        [1, 32, 16, 16]           --\n",
       "├─Dropout: 1-72                                                        [1, 64, 8, 8]             --\n",
       "├─Dropout: 1-73                                                        [1, 128, 4, 4]            --\n",
       "├─ModuleList: 1-74                                                     --                        (recursive)\n",
       "│    └─Sequential: 2-36                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-85                                               [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Upsample: 3-86                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-37                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-87                                               [1, 128, 16, 16]          (recursive)\n",
       "│    │    └─Upsample: 3-88                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-38                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-89                                               [1, 128, 8, 8]            (recursive)\n",
       "│    │    └─Upsample: 3-90                                             [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-39                                                [1, 128, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-91                                               [1, 128, 4, 4]            (recursive)\n",
       "│    │    └─Upsample: 3-92                                             [1, 128, 32, 32]          --\n",
       "├─CBAM: 1-75                                                           [1, 1024, 32, 32]         (recursive)\n",
       "│    └─ChannelGate: 2-40                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─Sequential: 3-93                                           [1, 1024]                 (recursive)\n",
       "│    │    └─Sequential: 3-94                                           [1, 1024]                 (recursive)\n",
       "│    └─SpatialGate: 2-41                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─ChannelPool: 3-95                                          [1, 2, 32, 32]            --\n",
       "│    │    └─BasicConv: 3-96                                            [1, 1, 32, 32]            (recursive)\n",
       "├─Conv2d: 1-76                                                         [1, 512, 32, 32]          (recursive)\n",
       "├─CBAM: 1-77                                                           [1, 1024, 32, 32]         --\n",
       "│    └─ChannelGate: 2-42                                               [1, 1024, 32, 32]         --\n",
       "│    │    └─Sequential: 3-97                                           [1, 1024]                 132,160\n",
       "│    │    └─Sequential: 3-98                                           [1, 1024]                 (recursive)\n",
       "│    └─SpatialGate: 2-43                                               [1, 1024, 32, 32]         --\n",
       "│    │    └─ChannelPool: 3-99                                          [1, 2, 32, 32]            --\n",
       "│    │    └─BasicConv: 3-100                                           [1, 1, 32, 32]            100\n",
       "├─Conv2d: 1-78                                                         [1, 512, 32, 32]          (recursive)\n",
       "├─CBAM: 1-79                                                           [1, 1024, 32, 32]         (recursive)\n",
       "│    └─ChannelGate: 2-44                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─Sequential: 3-101                                          [1, 1024]                 (recursive)\n",
       "│    │    └─Sequential: 3-102                                          [1, 1024]                 (recursive)\n",
       "│    └─SpatialGate: 2-45                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─ChannelPool: 3-103                                         [1, 2, 32, 32]            --\n",
       "│    │    └─BasicConv: 3-104                                           [1, 1, 32, 32]            (recursive)\n",
       "├─Conv2d: 1-80                                                         [1, 512, 32, 32]          (recursive)\n",
       "├─CBAM: 1-81                                                           [1, 1024, 32, 32]         (recursive)\n",
       "│    └─ChannelGate: 2-46                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─Sequential: 3-105                                          [1, 1024]                 (recursive)\n",
       "│    │    └─Sequential: 3-106                                          [1, 1024]                 (recursive)\n",
       "│    └─SpatialGate: 2-47                                               [1, 1024, 32, 32]         (recursive)\n",
       "│    │    └─ChannelPool: 3-107                                         [1, 2, 32, 32]            --\n",
       "│    │    └─BasicConv: 3-108                                           [1, 1, 32, 32]            (recursive)\n",
       "├─Conv2d: 1-82                                                         [1, 512, 32, 32]          (recursive)\n",
       "├─Head: 1-83                                                           [1, 11, 32, 32]           --\n",
       "│    └─Sequential: 2-48                                                [1, 11, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-109                                              [1, 512, 32, 32]          786,944\n",
       "│    │    └─Dropout: 3-110                                             [1, 512, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-111                                              [1, 11, 32, 32]           5,643\n",
       "========================================================================================================================\n",
       "Total params: 4,483,779\n",
       "Trainable params: 4,483,779\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 4.64\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.32\n",
       "Forward/backward pass size (MB): 92.96\n",
       "Params size (MB): 17.94\n",
       "Estimated Total Size (MB): 111.21\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thop import profile\n",
    "from thop import clever_format\n",
    "\n",
    "# CUDA 사용 가능 여부 확인\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else device\n",
    "print(f'Using {device} device')\n",
    "outer_model = ARC_Net(**model_args).to(device)\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(outer_model, input_size=((1, 11, 32, 32), (1, 33, 32, 32), (1, 33, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor = torch.zeros(1, 30, 30)\n",
    "# tensor = F.one_hot(tensor.long(), num_classes=11)\n",
    "# print(tensor.shape)\n",
    "# tensor = tensor.permute(0, 3, 1, 2)\n",
    "# print(tensor.shape)\n",
    "# tensor = tensor.squeeze(0)    \n",
    "# print(tensor.shape)\n",
    "# print(tensor.dtype)\n",
    "# tensor = tensor.to(torch.float32)  # 수정된 부분\n",
    "# print(tensor.dtype)\n",
    "# tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 11, 32, 32]) torch.Size([10, 1, 32, 32]) torch.Size([10, 33, 32, 32]) torch.Size([10, 33, 32, 32])\n",
      "torch.float32 torch.float32 torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "def one_hot_encoding(tensor):\n",
    "    tensor = F.one_hot(tensor.long(), num_classes=11)\n",
    "    tensor = tensor.permute(0, 3, 1, 2)\n",
    "    tensor = tensor.squeeze(0)\n",
    "    # 여기서 명시적으로 dtype을 float32로 설정합니다\n",
    "    tensor = tensor.to(torch.float32)  # 수정된 부분\n",
    "    return tensor\n",
    "\n",
    "\n",
    "class ARC_Dataset(Dataset):\n",
    "    def __init__(self, challenges, solution, task_data_num=1, example_data_num=3, max_combinations=10):\n",
    "        challenges = load_json(challenges)\n",
    "        solution = load_json(solution)\n",
    "        self.data = []\n",
    "        self.task_data_num = task_data_num\n",
    "        self.example_data_num = example_data_num\n",
    "        self.max_combinations = max_combinations\n",
    "\n",
    "        for key, value in challenges.items():\n",
    "            for i in range(len(value['test'])):\n",
    "                task_input = value['test'][i]['input']\n",
    "                task_output = solution[key][i]\n",
    "                example_list = value['train'].copy()\n",
    "\n",
    "                n_examples = len(example_list)  # 원래 예제의 개수\n",
    "\n",
    "                # 예제 수가 example_data_num보다 적으면 현재 작업의 예제를 복제하여 채움\n",
    "                if n_examples < self.example_data_num:\n",
    "                    while len(example_list) < self.example_data_num:\n",
    "                        example_list.append(random.choice(example_list))\n",
    "\n",
    "                    # 조합은 예제 리스트 자체로 설정\n",
    "                    ex_combinations = [tuple(example_list)]\n",
    "                else:\n",
    "                    # 예제의 조합 생성\n",
    "                    ex_combinations = list(combinations(example_list, self.example_data_num))\n",
    "\n",
    "                    # 조합의 수를 제한\n",
    "                    if len(ex_combinations) > self.max_combinations:\n",
    "                        ex_combinations = random.sample(ex_combinations, self.max_combinations)\n",
    "\n",
    "                for ex_combo in ex_combinations:\n",
    "                    ex_input = [ex['input'] for ex in ex_combo]\n",
    "                    ex_output = [ex['output'] for ex in ex_combo]\n",
    "\n",
    "                    # 데이터에 추가하면서 원래 예제의 개수도 포함\n",
    "                    self.data.append({\n",
    "                        'id': key,\n",
    "                        'input': task_input,\n",
    "                        'output': task_output,\n",
    "                        'ex_input': ex_input,\n",
    "                        'ex_output': ex_output,\n",
    "                        'num_original_examples': n_examples  # 원래 예제 개수 추가\n",
    "                    })\n",
    "\n",
    "        # 리스트를 데이터프레임으로 변환\n",
    "        self.df = pd.DataFrame(self.data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def pad_to_32x32(self, tensor):\n",
    "        if tensor.dim() == 2:\n",
    "            tensor = tensor.unsqueeze(0)\n",
    "        c, h, w = tensor.shape\n",
    "        pad_h = max(0, 32 - h)\n",
    "        pad_w = max(0, 32 - w)\n",
    "        \n",
    "        # 좌우 및 상하 패딩을 반반씩 나눠서 적용\n",
    "        padding = (pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2)\n",
    "        tensor = F.pad(tensor, padding, mode='constant', value=0)\n",
    "        \n",
    "        return tensor\n",
    "\n",
    "    def mapping_input(self, tensor):\n",
    "        mapping = {\n",
    "            1: random.randint(1, 10),\n",
    "            2: random.randint(11, 20),\n",
    "            3: random.randint(21, 30),\n",
    "            4: random.randint(31, 40),\n",
    "            5: random.randint(41, 50),\n",
    "            6: random.randint(51, 60),\n",
    "            7: random.randint(61, 70),\n",
    "            8: random.randint(71, 80),\n",
    "            9: random.randint(81, 90),\n",
    "            10: random.randint(91, 100)\n",
    "        }\n",
    "        temp_tensor = tensor.clone()\n",
    "        for k in mapping:\n",
    "            temp_tensor[temp_tensor == k] = -k  # 임시로 기존 값에 음수를 취해 중복을 피함\n",
    "\n",
    "        # 최종 매핑 적용\n",
    "        for k, v in mapping.items():\n",
    "            temp_tensor[temp_tensor == -k] = v\n",
    "        return temp_tensor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        task = self.df.iloc[idx]\n",
    "        \n",
    "        # task_input과 task_output 변환 및 패딩 추가\n",
    "        task_input = self.pad_to_32x32((torch.tensor(task['input'], dtype=torch.float32) + 1)) # [1, 32, 32]\n",
    "        task_output = self.pad_to_32x32((torch.tensor(task['output'], dtype=torch.float32) + 1)) # [1, 32, 32]\n",
    "        task_input = one_hot_encoding(task_input)\n",
    "        \n",
    "        # 입력 채널 차원 추가\n",
    "        if task_input.dim() == 2:\n",
    "            task_input = task_input.unsqueeze(0)  # [1, H, W]\n",
    "        if task_output.dim() == 2:\n",
    "            task_output = task_output.unsqueeze(0)  # [1, H, W]\n",
    "        \n",
    "        # 예제 입력과 출력 변환 및 패딩 추가\n",
    "        example_input = []\n",
    "        example_output = []\n",
    "        for ex_in, ex_out in zip(task['ex_input'], task['ex_output']):\n",
    "            ex_in_tensor = self.pad_to_32x32(torch.tensor(ex_in, dtype=torch.float32) + 1)\n",
    "            ex_out_tensor = self.pad_to_32x32(torch.tensor(ex_out, dtype=torch.float32) + 1)\n",
    "            ex_in_tensor = one_hot_encoding(ex_in_tensor)\n",
    "            ex_out_tensor = one_hot_encoding(ex_out_tensor)\n",
    "            \n",
    "            # 입력 채널 차원 추가\n",
    "            if ex_in_tensor.dim() == 2:\n",
    "                ex_in_tensor = ex_in_tensor.unsqueeze(0)  # [1, H, W]\n",
    "            if ex_out_tensor.dim() == 2:\n",
    "                ex_out_tensor = ex_out_tensor.unsqueeze(0)  # [1, H, W]\n",
    "            \n",
    "            example_input.append(ex_in_tensor)\n",
    "            example_output.append(ex_out_tensor)\n",
    "        \n",
    "        # 예제 입력과 출력을 채널 차원으로 결합\n",
    "        ex_inputs = torch.cat(example_input, dim=0)  # [n_examples * channels, H, W]\n",
    "        ex_outputs = torch.cat(example_output, dim=0)  # [n_examples * channels, H, W]\n",
    "        \n",
    "        return task_input, task_output, ex_inputs, ex_outputs\n",
    "\n",
    "# 사용 예제\n",
    "train_challenge = './kaggle/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "train_solution = \"./kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\"\n",
    "\n",
    "train_dataset = ARC_Dataset(train_challenge, train_solution)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "ti, to, ei, eo = next(iter(train_loader))\n",
    "print(ti.shape, to.shape, ei.shape, eo.shape)\n",
    "print(ti.dtype, to.dtype, ei.dtype, eo.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_accuracy(predictions, targets, ignore_index=0):\n",
    "    pred_classes = predictions.argmax(dim=1)  # [batch_size, H, W]\n",
    "    targets = targets.squeeze(1)  # [batch_size, H, W]\n",
    "    \n",
    "    # 마스크 생성: gt가 ignore_index가 아닌 부분만 True\n",
    "    mask = (targets != ignore_index)\n",
    "    \n",
    "    # 이미지 단위 정확도 계산\n",
    "    correct_samples = pred_classes.eq(targets)  # [batch_size, H, W]\n",
    "    correct_samples = correct_samples & mask  # 마스크 적용\n",
    "    correct_samples = correct_samples.view(targets.size(0), -1).all(dim=1).sum().item()\n",
    "    total_samples = targets.size(0)\n",
    "    \n",
    "    # 픽셀 단위 정확도 계산\n",
    "    correct_pixels = (pred_classes.eq(targets) & mask).sum().item()\n",
    "    total_pixels = mask.sum().item()\n",
    "    \n",
    "    return correct_samples, total_samples, correct_pixels, total_pixels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def visualize_predictions(inputs, targets, predictions, condition):\n",
    "    if condition:\n",
    "        # 입력 이미지와 예측 결과를 CPU로 이동\n",
    "        inputs = inputs.cpu().numpy()\n",
    "        targets = targets.cpu().numpy()\n",
    "        predictions = predictions.detach().cpu().numpy()  # detach()로 그래디언트 추적 중단\n",
    "\n",
    "        # 첫 번째 배치의 첫 번째 이미지를 시각화\n",
    "        input_image = inputs.argmax(axis=1)[0]            # shape: (C, H, W)\n",
    "        target_image = targets[0]          # shape: (C, H, W) 또는 (H, W)\n",
    "        prediction_image = predictions.argmax(axis=1)[0]  # shape: (H, W)\n",
    "\n",
    "        # 입력 이미지 형태 조정\n",
    "        if input_image.ndim == 3 and input_image.shape[0] == 1:\n",
    "            # 채널 차원이 1인 경우, 채널 차원 제거 (단일 채널 이미지)\n",
    "            input_image = input_image.squeeze(0)  # shape: (H, W)\n",
    "        elif input_image.ndim == 3 and input_image.shape[0] == 3:\n",
    "            # RGB 이미지를 범위 0~10으로 정규화하여 컬러맵에 적용\n",
    "            input_image = input_image.mean(axis=0)  # shape: (H, W)로 변환 (3채널을 단일값으로)\n",
    "\n",
    "        # 타겟 이미지와 예측 이미지 형태 조정\n",
    "        if target_image.ndim == 3 and target_image.shape[0] == 1:\n",
    "            target_image = target_image.squeeze(0)  # shape: (H, W)\n",
    "\n",
    "        target_image = target_image.astype(int)      # 정수형으로 변환\n",
    "        prediction_image = prediction_image.astype(int)  # 정수형으로 변환\n",
    "\n",
    "        # 컬러 맵 정의 (0~10 값을 위한 11개의 색상)\n",
    "        color_list = ['black', 'blue', 'red', 'green', 'yellow', 'purple', \n",
    "                      'orange', 'pink', 'gray', 'brown', 'cyan']\n",
    "        cmap = ListedColormap(color_list)\n",
    "\n",
    "        # 시각화를 위한 플롯 생성\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "        # 입력 이미지에 컬러맵 적용하여 표시\n",
    "        axes[0].imshow(input_image, cmap=cmap, vmin=0, vmax=10)\n",
    "        axes[0].set_title('Input Image (with Color Map)')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # 타겟 이미지 표시 (색상 맵 적용)\n",
    "        axes[1].imshow(target_image, cmap=cmap, vmin=0, vmax=10)  # 범위를 0~10으로 변경\n",
    "        axes[1].set_title('Ground Truth')\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        # 예측 결과 표시 (색상 맵 적용)\n",
    "        axes[2].imshow(prediction_image, cmap=cmap, vmin=0, vmax=10)  # 범위를 0~10으로 변경\n",
    "        axes[2].set_title('Prediction')\n",
    "        axes[2].axis('off')\n",
    "\n",
    "        # 범례를 플롯 내에 표시\n",
    "        patches = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color_list[i], markersize=10, label=str(i)) for i in range(11)]\n",
    "        plt.legend(handles=patches, bbox_to_anchor=(1.05, 0.5), loc='center left', borderaxespad=0.)\n",
    "\n",
    "        plt.tight_layout()  # 레이아웃을 자동으로 조정\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000:   2%|▏         | 2/101 [00:02<02:01,  1.23s/it, loss=2.2005]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_challenge = './kaggle/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "train_solution = \"./kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\"\n",
    "eval_challenge = \"./kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json\"\n",
    "eval_solution = \"./kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\"\n",
    "\n",
    "train_args = {\n",
    "    'challenges': train_challenge,\n",
    "    'solution': train_solution,\n",
    "    'num_classes': 11,\n",
    "    'batch_size': 48,\n",
    "    'epochs': 1000,\n",
    "    'learning_rate': 0.001,\n",
    "}\n",
    "\n",
    "model_args = {\n",
    "    'dims': (32,64,128),\n",
    "    'heads': 4,\n",
    "    'ff_expansion': 4,\n",
    "    'reduction_ratio': (4,2,2),\n",
    "    'num_layers': (2,3,4),\n",
    "    'channels': 11,\n",
    "    'num_classes': 11,\n",
    "    'kernel_stride_paddings': ((3, 1, 1),(3, 2, 1),(3, 2, 1))\n",
    "    }\n",
    "\n",
    "def criterion(y_pred, y):\n",
    "    y = y.long().squeeze(1)\n",
    "    weight = torch.ones(train_args['num_classes']).to(y.device)\n",
    "    weight[0] = 0.04\n",
    "    weight[1] = 0.8\n",
    "    ce = F.cross_entropy(y_pred, y, weight=weight) \n",
    "    return ce\n",
    "\n",
    "\n",
    "# CUDA 사용 가능 여부 확인\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else device\n",
    "print(f'Using {device} device')\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "train_dataset = ARC_Dataset(train_challenge, train_solution)\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_args['batch_size'], shuffle=True)\n",
    "\n",
    "eval_dataset = ARC_Dataset(eval_challenge, eval_solution)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=train_args['batch_size'], shuffle=False)\n",
    "\n",
    "# 모델 정의\n",
    "model = ARC_Net(**model_args).to(device)\n",
    "\n",
    "# 옵티마이저 정의\n",
    "optimizer = optim.AdamW(model.parameters(), lr=train_args['learning_rate'])\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct_samples = 0\n",
    "    total_samples = 0\n",
    "    total_correct_pixels = 0\n",
    "    total_pixels = 0\n",
    "\n",
    "    last_task_inputs = None\n",
    "    last_task_outputs = None\n",
    "    last_output = None\n",
    "\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch+1}/{train_args[\"epochs\"]}', leave=False)\n",
    "\n",
    "    for batch_idx, (task_inputs, task_outputs, ex_inputs, ex_outputs) in progress_bar:\n",
    "        task_inputs = task_inputs.to(device, non_blocking=True)\n",
    "        task_outputs = task_outputs.to(device, non_blocking=True)\n",
    "        ex_inputs = ex_inputs.to(device, non_blocking=True)\n",
    "        ex_outputs = ex_outputs.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(task_inputs, ex_inputs, ex_outputs)\n",
    "\n",
    "        # 손실 함수 계산\n",
    "        loss = criterion(output, task_outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        correct_samples, batch_total_samples, correct_pixels, batch_total_pixels = calculate_accuracy(output, task_outputs, ignore_index=0)\n",
    "        total_correct_samples += correct_samples\n",
    "        total_samples += batch_total_samples\n",
    "        total_correct_pixels += correct_pixels\n",
    "        total_pixels += batch_total_pixels\n",
    "\n",
    "        # 마지막 배치의 데이터 저장\n",
    "        last_task_inputs = task_inputs.clone()\n",
    "        last_task_outputs = task_outputs.clone()\n",
    "        last_output = output.clone()\n",
    "        \n",
    "        # 프로그레스 바 업데이트\n",
    "        progress_bar.set_postfix(loss=f'{loss.item():.4f}')\n",
    "    \n",
    "    # 에포크가 끝난 후\n",
    "    avg_sample_accuracy = 100. * total_correct_samples / total_samples\n",
    "    avg_pixel_accuracy = 100. * total_correct_pixels / total_pixels\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{train_args[\"epochs\"]}] Complete | Average Loss: {avg_loss:.6f} | Training Sample Accuracy: {avg_sample_accuracy:.2f}% | Training Pixel Accuracy: {avg_pixel_accuracy:.2f}%')\n",
    "\n",
    "    # 에포크가 10의 배수일 때만 시각화 수행\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        visualize_predictions(last_task_inputs, last_task_outputs, last_output, condition=True)\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct_samples = 0\n",
    "    total_samples = 0\n",
    "    total_correct_pixels = 0\n",
    "    total_pixels = 0\n",
    "\n",
    "    last_task_inputs = None\n",
    "    last_task_outputs = None\n",
    "    last_output = None\n",
    "\n",
    "    progress_bar = tqdm(enumerate(eval_loader), total=len(eval_loader), desc='Testing', leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (task_inputs, task_outputs, ex_inputs, ex_outputs) in progress_bar:\n",
    "            task_inputs = task_inputs.to(device, non_blocking=True)\n",
    "            task_outputs = task_outputs.to(device, non_blocking=True)\n",
    "            ex_inputs = ex_inputs.to(device, non_blocking=True)\n",
    "            ex_outputs = ex_outputs.to(device, non_blocking=True)\n",
    "\n",
    "            output = model(task_inputs, ex_inputs, ex_outputs)\n",
    "\n",
    "            # 손실 함수 계산\n",
    "            loss = criterion(output, task_outputs)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 정확도 계산\n",
    "            correct_samples, batch_total_samples, correct_pixels, batch_total_pixels = calculate_accuracy(output, task_outputs, ignore_index=0)\n",
    "            total_correct_samples += correct_samples\n",
    "            total_samples += batch_total_samples\n",
    "            total_correct_pixels += correct_pixels\n",
    "            total_pixels += batch_total_pixels\n",
    "\n",
    "            # 마지막 배치의 데이터 저장\n",
    "            last_task_inputs = task_inputs.clone()\n",
    "            last_task_outputs = task_outputs.clone()\n",
    "            last_output = output.clone()\n",
    "            \n",
    "            # 프로그레스 바 업데이트\n",
    "            progress_bar.set_postfix(loss=f'{loss.item():.4f}')\n",
    "    \n",
    "    avg_sample_accuracy = 100. * total_correct_samples / total_samples\n",
    "    avg_pixel_accuracy = 100. * total_correct_pixels / total_pixels\n",
    "    avg_loss = total_loss / len(eval_loader)\n",
    "\n",
    "    print(f'Test Average Loss: {avg_loss:.6f} | Test Sample Accuracy: {avg_sample_accuracy:.2f}% | Test Pixel Accuracy: {avg_pixel_accuracy:.2f}%')\n",
    "\n",
    "    # 에포크가 10의 배수일 때만 시각화 수행\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        visualize_predictions(last_task_inputs, last_task_outputs, last_output, condition=True)\n",
    "\n",
    "# 학습 실행\n",
    "for epoch in range(train_args['epochs']):  \n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
